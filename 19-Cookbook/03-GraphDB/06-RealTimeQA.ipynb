{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635d8ebb",
   "metadata": {},
   "source": [
    "# Real-Time GraphRAG QA\n",
    "\n",
    "- Author: [Jongcheol Kim](https://github.com/greencode-99)\n",
    "- Design: \n",
    "- Peer Review: [Heesun Moon](https://github.com/MoonHeesun), [Taylor(Jihyun Kim)](https://github.com/Taylor0819)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial provides **GraphRAG QA** functionality that extracts knowledge from PDF documents and enables natural language queries through a **Neo4j graph database**. After users upload PDF documents, they are processed using **OpenAI's GPT models** (e.g., `gpt-4o` and `text-ada-002`) to extract entities and relationships.\n",
    "\n",
    "The extracted information is stored in a **Neo4j graph database**. Users can then interact with the graph in real-time by asking natural language questions, which are converted into **Cypher queries** to retrieve answers from the graph.\n",
    "\n",
    "\n",
    "### Features\n",
    "\n",
    "- **Real-time GraphRAG:** Enables real-time knowledge extraction from documents and supports interactive querying.\n",
    "- **Modular and Configurable:** Users can set up their own credentials for `OpenAI` and `Neo4j`.\n",
    "- **Natural Language Interface:** Ask questions in plain English and get answers from the graph database.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Neo4j Database Connection](#neo4j-database-connection)\n",
    "- [PDF Processing](#pdf-processing)\n",
    "- [Graph Transformation](#graph-transformation)\n",
    "- [Vector Index Creation](#vector-index-creation)\n",
    "- [QA Chain Setup](#qa-chain-setup)\n",
    "- [Define QA Function](#define-qa-function)\n",
    "- [Usage Example](#usage-example)\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain Documentation: Neo4j Integration](https://python.langchain.com/docs/integrations/retrievers/self_query/neo4j_self_query/#filter-k)\n",
    "- [Neo4j Graph Labs](https://neo4j.com/labs/genai-ecosystem/langchain/)\n",
    "- [LangChain Graph QA Chain](https://python.langchain.com/api_reference/community/chains/langchain_community.chains.graph_qa.base.GraphQAChain.html#graphqachain)\n",
    "- [Graphy v1](https://github.com/AIAnytime/Graphy-v1)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7aba4",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21943adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25ec196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langchain\",\n",
    "        \"langchain_neo4j\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_text_splitters\",\n",
    "        \"langchain_experimental\",\n",
    "        \"pypdf\",\n",
    "        \"json-repair\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9065ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Real-Time GraphRAG QA\",\n",
    "        \"NEO4J_URL\": \"\",\n",
    "        \"NEO4J_USERNAME\": \"\",\n",
    "        \"NEO4J_PASSWORD\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345db77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neo4j-section",
   "metadata": {},
   "source": [
    "## Neo4j Database Connection\n",
    "\n",
    "This tutorial uses Neo4j and Neo4j Sandbox for graph database construction.\n",
    " \n",
    "`Neo4j Sandbox` is an online graph database that allows you to easily build a **free cloud-based Neo4j instance**, allowing you to experiment with graph databases in the cloud environment without local installation.\n",
    "\n",
    "[Note] \n",
    "Neo4j can be set up in several different ways:\n",
    "\n",
    "1. [`Neo4j Desktop`](https://neo4j.com/docs/operations-manual/current/installation/) :  A desktop application for local development\n",
    "\n",
    "2. [`Neo4j Sandbox` ](https://neo4j.com/sandbox/) : A free, cloud-based platform for working with graph databases\n",
    "\n",
    "3. [`Docker` ](https://neo4j.com/docs/operations-manual/current/docker/) : Run Neo4j in a container using the official Neo4j Docker image\n",
    "\n",
    "### Setup Neo4j Sandbox\n",
    "- Go to Neo4j Sandbox and click the \"+ New Project\" button. Select your desired dataset to create a database.\n",
    "\n",
    "![select-dataset](./assets/realtime-qa-setup-01.png)\n",
    "\n",
    "- After creation, click the toggle to see example connection code provided for different programming languages. You can easily connect using the neo4j-driver library.\n",
    "\n",
    "![neo4j-driver](./assets/realtime-qa-setup-02.png)\n",
    "\n",
    "- To connect the graph database with LangChain, you'll need the connection details from this section.\n",
    "\n",
    "![connection-details](./assets/realtime-qa-setup-03.png)\n",
    "\n",
    "\n",
    "The following code connects to the Neo4j database and initializes the necessary components for our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea4aa3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Neo4j database\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_neo4j.graphs.neo4j_graph import Neo4jGraph\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set\")\n",
    "\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URL\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "\n",
    "def connect_to_neo4j():\n",
    "    try:\n",
    "        graph = Neo4jGraph(\n",
    "            url=NEO4J_URL, username=NEO4J_USERNAME, password=NEO4J_PASSWORD\n",
    "        )\n",
    "        print(\"Successfully connected to Neo4j database\")\n",
    "        return graph\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to Neo4j: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "graph = connect_to_neo4j()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pdf-processing",
   "metadata": {},
   "source": [
    "## PDF Processing\n",
    "\n",
    "\n",
    "Here's how we process PDF documents and extract text from them.\n",
    "\n",
    "First, we use `PyPDFLoader` to load the PDF file and split it into individual pages. Then, we use `RecursiveCharacterTextSplitter` to break these pages down into manageable chunks. We set each chunk to be 200 characters long, with a 40-character overlap between chunks to maintain smooth transitions and context.\n",
    "\n",
    "Once all the splitting work is complete, we begin our text cleanup process. For each piece of document, we remove any newline characters and include source information so we can track where the content originated. All of this cleaned-up information gets neatly organized into a list of Document objects.\n",
    "\n",
    "This approach helps us transform complex PDF documents into a format that's much more suitable for AI processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f8855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def process_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load_and_split()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40)\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "\n",
    "    lc_docs = []\n",
    "    for doc in docs:\n",
    "        lc_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content.replace(\"\\n\", \"\"),\n",
    "                metadata={\"source\": file_path},\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return lc_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graph-transform",
   "metadata": {},
   "source": [
    "## Graph Transformation\n",
    "\n",
    "Here's how to transform extracted text into a graph structure using our transformation function.\n",
    "\n",
    "First, we initialize the graph database by clearing any existing nodes and relationships. We then define a set of allowed nodes and their permitted relationships:\n",
    "- `Allowed nodes` : [\"Device\", \"PowerSource\", \"OperatingSystem\", \"ConnectionStatus\", \"Software\", \"Action\"]\n",
    "- `Permitted relationships` : [\"USES_POWER\", \"OPERATES_ON\", \"HAS_STATUS\", \"REQUIRES\", \"PERFORMS\"]\n",
    "\n",
    "For demonstration purposes, these nodes and relationships were defined using the `gpt-4o` model.\n",
    "\n",
    "We then create a graph transformer using `LLMGraphTransformer` and configure it with our defined nodes and relationships. To keep things simple, we set both node and relationship properties to false. This transformer takes our document chunks and converts them into graph documents, which are then added to our Neo4j database along with their source information.\n",
    "\n",
    "This whole process transforms our text data into a structured graph format, making it much easier to query and analyze relationships between different entities in our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed22e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "\n",
    "def transform_to_graph(docs, graph):\n",
    "    cypher = \"\"\"\n",
    "    MATCH (n)\n",
    "    DETACH DELETE n;\n",
    "    \"\"\"\n",
    "    graph.query(cypher)\n",
    "\n",
    "    allowed_nodes = [\n",
    "        \"Device\",\n",
    "        \"PowerSource\",\n",
    "        \"OperatingSystem\",\n",
    "        \"ConnectionStatus\",\n",
    "        \"Software\",\n",
    "        \"Action\",\n",
    "    ]\n",
    "    allowed_relationships = [\n",
    "        \"USES_POWER\",\n",
    "        \"OPERATES_ON\",\n",
    "        \"HAS_STATUS\",\n",
    "        \"REQUIRES\",\n",
    "        \"PERFORMS\",\n",
    "    ]\n",
    "\n",
    "    transformer = LLMGraphTransformer(\n",
    "        llm=llm,\n",
    "        allowed_nodes=allowed_nodes,\n",
    "        allowed_relationships=allowed_relationships,\n",
    "        node_properties=False,\n",
    "        relationship_properties=False,\n",
    "    )\n",
    "\n",
    "    graph_documents = transformer.convert_to_graph_documents(docs)\n",
    "    graph.add_graph_documents(graph_documents, include_source=True)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vector-index",
   "metadata": {},
   "source": [
    "## Vector Index Creation\n",
    "\n",
    "\n",
    "Here's how to create a vector index using our vector index creation function.\n",
    "\n",
    "First, we use `Neo4jVector.from_existing_graph()` to create a vector index from our existing Neo4j graph database - this is what allows us to perform similarity searches on our graph data.\n",
    "\n",
    "The function needs several important parameters to work properly:\n",
    "- We use `OpenAI` embeddings for vector representation\n",
    "- We provide database connection parameters (`url`, `username`, `password`)\n",
    "- For node configuration, we specify `\"Patient\"` as the `node_label` for indexing\n",
    "- We define `text_node_properties` to use both `\"id\"` and `\"text\"` for content\n",
    "- We specify where to store vector embeddings using the `embedding_node_property` parameter\n",
    "\n",
    "For the indexing setup, we create two types of indices:\n",
    "- A vector index and a keyword index (specified by `index_name` and `keyword_index_name`)\n",
    "- We set the `search_type` to `\"hybrid\"`, enabling both vector and keyword-based searching\n",
    "\n",
    "This comprehensive setup creates an **efficient system** for performing **similarity searches** and **hybrid querying** in our graph database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3607f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j.vectorstores.neo4j_vector import Neo4jVector\n",
    "\n",
    "\n",
    "def create_vector_index():\n",
    "    index = Neo4jVector.from_existing_graph(\n",
    "        embedding=embeddings,\n",
    "        url=NEO4J_URL,\n",
    "        username=NEO4J_USERNAME,\n",
    "        password=NEO4J_PASSWORD,\n",
    "        database=\"neo4j\",\n",
    "        node_label=\"Patient\",\n",
    "        text_node_properties=[\"id\", \"text\"],\n",
    "        embedding_node_property=\"embedding\",\n",
    "        index_name=\"vector_index\",\n",
    "        keyword_index_name=\"entity_index\",\n",
    "        search_type=\"hybrid\",\n",
    "    )\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qa-chain",
   "metadata": {},
   "source": [
    "## QA Chain Setup\n",
    "\n",
    "\n",
    "Here's how to create a powerful question-answering chain using the `GraphCypherQAChain`.\n",
    "\n",
    "First, we create a custom prompt template that helps generate Cypher queries. This template is quite comprehensive - it includes all the available relationship types in our database like `MENTIONS`, `PERFORMS`, `USES_POWER`, `HAS_STATUS`, `OPERATES_ON`, and `REQUIRES`. It also provides an example query structure to ensure proper formatting and includes a placeholder where we'll insert the user's question.\n",
    "\n",
    "Once we have our template ready, we create a `GraphCypherQAChain` with several important configurations:\n",
    "- We use our configured `llm` for query generation\n",
    "- We connect it to our `graph` database\n",
    "- We incorporate our `cypher_prompt` template\n",
    "- We enable `verbose` mode for detailed logging\n",
    "- We set `return_intermediate_steps` to see what's happening under the hood\n",
    "- We set `allow_dangerous_requests` to true for handling complex queries\n",
    "- We limit our results to the top 3 matches with `top_k`\n",
    "\n",
    "This whole setup creates a **powerful chain** that can take **natural language questions** from users, convert them into **proper Cypher queries**, and fetch relevant answers from our graph database. It's like having a translator that converts human questions into database language and back again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc16adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "def setup_qa_chain(graph):\n",
    "    template = \"\"\"\n",
    "    Generate a Cypher query to find information about the question.\n",
    "    Use only these relationships that exist in the database: MENTIONS, PERFORMS, USES_POWER, HAS_STATUS, OPERATES_ON, REQUIRES\n",
    "    \n",
    "    Example query structure:\n",
    "    MATCH (d:Document)-[:MENTIONS]->(a:Action)\n",
    "    WHERE toLower(d.text) CONTAINS 'keyword'\n",
    "    RETURN d.text as answer\n",
    "    \n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    question_prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "    qa = GraphCypherQAChain.from_llm(\n",
    "        llm=llm,\n",
    "        graph=graph,\n",
    "        cypher_prompt=question_prompt,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "        allow_dangerous_requests=True,\n",
    "        top_k=3,\n",
    "    )\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e962709",
   "metadata": {},
   "source": [
    "## Define QA Function\n",
    "\n",
    "Here's how this function combines a **graph database query** with an **LLM fallback** to provide answers efficiently.\n",
    "\n",
    "First, it searches the graph database using a `Cypher query`. It looks for `Document` nodes connected via `MENTIONS` relationships that contain the question's keyword in their text. This is the primary way the function tries to find answers.\n",
    "\n",
    "If the first query doesn't return a result, it splits the question into individual words and searches using each word as a keyword. This approach helps when a single keyword doesn't match exactly but parts of the question might.\n",
    "\n",
    "The function includes several fallback mechanisms:\n",
    "- If no answer is found in the database, the question is passed to an `LLM`\n",
    "- The `LLM` processes the query and generates an answer independently\n",
    "- The entire process is wrapped in a `try-except` block for smooth error handling\n",
    "- Users receive friendly error messages if something goes wrong\n",
    "\n",
    "The function follows a clear decision path:\n",
    "- Return database answer if found\n",
    "- Use LLM's answer if database search fails\n",
    "- Ask user to rephrase if both methods fail\n",
    "\n",
    "This **hybrid approach** ensures flexibility, combining the speed of database queries with the depth of LLM-generated answers. It's perfect for handling both structured and unstructured data queries seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc5cdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(qa, question):\n",
    "    try:\n",
    "        base_query = \"\"\"\n",
    "        MATCH (d:Document)-[:MENTIONS]->(a)\n",
    "        WHERE toLower(d.text) CONTAINS toLower($keyword)\n",
    "        RETURN DISTINCT d.text as answer\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "\n",
    "        result = graph.query(base_query, {\"keyword\": question.lower()})\n",
    "\n",
    "        if not result:\n",
    "            keywords = question.lower().split()\n",
    "            for keyword in keywords:\n",
    "                if len(keyword) > 3:\n",
    "                    result = graph.query(base_query, {\"keyword\": keyword})\n",
    "                    if result:\n",
    "                        break\n",
    "\n",
    "        if result and len(result) > 0:\n",
    "            return result[0][\"answer\"]\n",
    "\n",
    "        qa_result = qa.invoke({\"query\": question})\n",
    "        if qa_result and \"result\" in qa_result:\n",
    "            return qa_result[\"result\"]\n",
    "\n",
    "        return \"Unable to find an answer. Please try rephrasing your question.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return \"An error occurred while processing your question.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-example",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "Here's a practical example.\n",
    "- I used the following document for this demonstration.\n",
    "- Please download the document using the link below and save it to the `data` folder.\n",
    "\n",
    "**Document Details**\n",
    "- Product Name: `Microsoft Bluetooth Notebook Mouse 5000`\n",
    "- Document Type: **User Manual**\n",
    "- File Size: `1.18 MB`\n",
    "- Pages: `7`\n",
    "\n",
    "**Related Documents**\n",
    "- `Laser Desktop Keyboard 6000 v3.0` Quick Start Manual\n",
    "- `Bluetooth Notebook Mouse 5000` User Manual\n",
    "- `Laser Mouse 6000` Specifications\n",
    "- `Mouse 6000` Getting Started Manual\n",
    "- `Compact Optical Mouse 500` Quick Start Manual\n",
    "\n",
    "**Download Link**\n",
    "[Microsoft Bluetooth Notebook Mouse 5000 Manual](https://www.manualslib.com/download/1876132/Microsoft-Bluetooth-Notebook-Mouse-5000.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c13095",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"data/bluetooth_notebook_mouse_5000.pdf\"\n",
    "\n",
    "# PDF Processing\n",
    "docs = process_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "298eec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Transformation\n",
    "# The graph creation process may take a long time depending on the size of the document.\n",
    "# For a 7-page document, it takes about 2 minutes.\n",
    "graph = transform_to_graph(docs, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4abd09e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State of Neo4j Database:\n",
      "=== Node Types and Count ===\n",
      "[{'labels': ['Document'], 'count': 27}, {'labels': ['Device'], 'count': 19}, {'labels': ['Connectionstatus'], 'count': 10}, {'labels': ['Action'], 'count': 22}, {'labels': ['Operatingsystem'], 'count': 3}, {'labels': ['Software'], 'count': 11}, {'labels': ['Powersource'], 'count': 3}]\n",
      "\n",
      "=== Relationship Types and Count ===\n",
      "[{'type': 'MENTIONS', 'count': 102}, {'type': 'PERFORMS', 'count': 22}, {'type': 'HAS_STATUS', 'count': 12}, {'type': 'OPERATES_ON', 'count': 7}, {'type': 'REQUIRES', 'count': 15}, {'type': 'USES_POWER', 'count': 4}]\n",
      "\n",
      "=== Sample Graph Structure ===\n",
      "[{'n': {'text': 'www.microsoft.com/hardware/supportwww.microsoft.com/hardware/productguidewww.microsoft.com/hardware/downloads1  Insira duas pilhas alcalinas do tipo AAA e ligue o mouse.', 'source': 'data/bluetooth_notebook_mouse_5000.pdf', 'id': '822061c9baab0a2a3b354693240b1f00'}, 'r': ({'text': 'www.microsoft.com/hardware/supportwww.microsoft.com/hardware/productguidewww.microsoft.com/hardware/downloads1  Insira duas pilhas alcalinas do tipo AAA e ligue o mouse.', 'source': 'data/bluetooth_notebook_mouse_5000.pdf', 'id': '822061c9baab0a2a3b354693240b1f00'}, 'MENTIONS', {'id': 'Turn_On'}), 'm': {'id': 'Turn_On'}}, {'n': {'text': '2  Para conectar o mouse ao computador:a. Pressione e mantenha pressionado o botão connect até que a luz na parte superior do mouse comece a piscar em vermelho e verde.', 'source': 'data/bluetooth_notebook_mouse_5000.pdf', 'id': '308ad55429d13b32eb709ff8320bb02f'}, 'r': ({'text': '2  Para conectar o mouse ao computador:a. Pressione e mantenha pressionado o botão connect até que a luz na parte superior do mouse comece a piscar em vermelho e verde.', 'source': 'data/bluetooth_notebook_mouse_5000.pdf', 'id': '308ad55429d13b32eb709ff8320bb02f'}, 'MENTIONS', {'id': 'Mouse'}), 'm': {'id': 'Mouse'}}, {'n': {'text': '2  Para conectar o mouse ao computador:a. Pressione e mantenha pressionado o botão connect até que a luz na parte superior do mouse comece a piscar em vermelho e verde.', 'source': 'data/bluetooth_notebook_mouse_5000.pdf', 'id': '308ad55429d13b32eb709ff8320bb02f'}, 'r': ({'text': '2  Para conectar o mouse ao computador:a. Pressione e mantenha pressionado o botão connect até que a luz na parte superior do mouse comece a piscar em vermelho e verde.', 'source': 'data/bluetooth_notebook_mouse_5000.pdf', 'id': '308ad55429d13b32eb709ff8320bb02f'}, 'MENTIONS', {'id': 'Computer'}), 'm': {'id': 'Computer'}}]\n"
     ]
    }
   ],
   "source": [
    "# Data Inspection\n",
    "def inspect_neo4j_data(graph):\n",
    "    # All Nodes Query\n",
    "    nodes_query = \"\"\"\n",
    "    MATCH (n)\n",
    "    RETURN DISTINCT labels(n) as labels, count(*) as count\n",
    "    \"\"\"\n",
    "    print(\"=== Node Types and Count ===\")\n",
    "    nodes = graph.query(nodes_query)\n",
    "    print(nodes)\n",
    "\n",
    "    # All Relationships Query\n",
    "    rels_query = \"\"\"\n",
    "    MATCH ()-[r]->()\n",
    "    RETURN DISTINCT type(r) as type, count(*) as count\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Relationship Types and Count ===\")\n",
    "    relationships = graph.query(rels_query)\n",
    "    print(relationships)\n",
    "\n",
    "    # Sample Graph Structure\n",
    "    sample_query = \"\"\"\n",
    "    MATCH (n)-[r]->(m)\n",
    "    RETURN n, r, m\n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Sample Graph Structure ===\")\n",
    "    sample = graph.query(sample_query)\n",
    "    print(sample)\n",
    "\n",
    "\n",
    "print(\"Current State of Neo4j Database:\")\n",
    "inspect_neo4j_data(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b64ca94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Index Creation\n",
    "index = create_vector_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "601352ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA Chain Setup\n",
    "qa = setup_qa_chain(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a43a518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What happens when you press and hold the connect button?\n",
      "Answer: control panel, and in category view, locate hardware and sound, and then select add a device.c. When the mouse is listed, select  it, and follow the instructions.\n"
     ]
    }
   ],
   "source": [
    "question = \"What happens when you press and hold the connect button?\"\n",
    "answer = ask_question(qa, question)\n",
    "print(f\"\\nQuestion: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b2f3cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing multiple questions:\n",
      "\n",
      "Q: What happens when you press and hold the connect button?\n",
      "A: control panel, and in category view, locate hardware and sound, and then select add a device.c. When the mouse is listed, select  it, and follow the instructions.\n",
      "\n",
      "Q: What type of batteries does this mouse use?\n",
      "A: type control panel, select control panel from the search results, and then select add devices and printers .WindoWs 7: On your computer, from the start menu, select\n",
      "\n",
      "Q: How do I connect to Windows 8?\n",
      "A: 2  Pour connecter la souris à votre ordinateur :a. Maintenez enfoncé le bouton « connect » jusqu’à ce que le voyant sur le dessus de la souris clignote en rouge et vert.\n",
      "\n",
      "Q: Where is the connect button located?\n",
      "A: 2  Pour connecter la souris à votre ordinateur :a. Maintenez enfoncé le bouton « connect » jusqu’à ce que le voyant sur le dessus de la souris clignote en rouge et vert.\n"
     ]
    }
   ],
   "source": [
    "# Multiple Test\n",
    "def test_qa():\n",
    "    questions = [\n",
    "        \"What happens when you press and hold the connect button?\",\n",
    "        \"What type of batteries does this mouse use?\",\n",
    "        \"How do I connect to Windows 8?\",\n",
    "        \"Where is the connect button located?\",\n",
    "    ]\n",
    "\n",
    "    print(\"\\nTesting multiple questions:\")\n",
    "    for q in questions:\n",
    "        print(f\"\\nQ: {q}\")\n",
    "        print(f\"A: {ask_question(qa, q)}\")\n",
    "\n",
    "\n",
    "# Run\n",
    "test_qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a63e946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database Content Check:\n",
      "\n",
      "Query: MATCH (d:Document) WHERE toLower(d.text) CONTAINS 'connect button' RETURN d.text LIMIT 1\n",
      "Result: [{'d.text': '2  To connect the mouse to your computer:a. Press and hold the connect button until the light on the top of the mouse flashes red and green.b. WindoWs 8: On your computer, press the Windows key,'}]\n",
      "\n",
      "Query: MATCH (a:Action) WHERE toLower(a.id) CONTAINS 'connect' RETURN a.id\n",
      "Result: [{'a.id': 'Connecter'}, {'a.id': 'Connect Button'}, {'a.id': 'Connect_Button'}]\n",
      "\n",
      "Query: MATCH (d:Document)-[:MENTIONS]->(a) RETURN DISTINCT labels(a) as node_types\n",
      "Result: [{'node_types': ['Connectionstatus']}, {'node_types': ['Device']}, {'node_types': ['Action']}, {'node_types': ['Operatingsystem']}, {'node_types': ['Software']}, {'node_types': ['Powersource']}]\n"
     ]
    }
   ],
   "source": [
    "# Debugging\n",
    "def check_database_content():\n",
    "    queries = [\n",
    "        \"MATCH (d:Document) WHERE toLower(d.text) CONTAINS 'connect button' RETURN d.text LIMIT 1\",\n",
    "        \"MATCH (a:Action) WHERE toLower(a.id) CONTAINS 'connect' RETURN a.id\",\n",
    "        \"MATCH (d:Document)-[:MENTIONS]->(a) RETURN DISTINCT labels(a) as node_types\",\n",
    "    ]\n",
    "\n",
    "    print(\"\\nDatabase Content Check:\")\n",
    "    for query in queries:\n",
    "        result = graph.query(query)\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(f\"Result: {result}\")\n",
    "\n",
    "\n",
    "check_database_content()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

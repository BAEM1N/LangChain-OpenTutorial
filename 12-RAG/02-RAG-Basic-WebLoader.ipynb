{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "635d8ebb",
      "metadata": {},
      "source": [
        "# RAG Basic WebBaseLoader\n",
        "\n",
        "- Author: [Sunyoung Park (architectyou)](https://github.com/architectyou)\n",
        "- Design: \n",
        "- Peer Review: [sunworl](https://github.com/sunworl), [jae-hoya](https://github.com/jae-hoya)\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/99-TEMPLATE/00-BASE-TEMPLATE-EXAMPLE.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/99-TEMPLATE/00-BASE-TEMPLATE-EXAMPLE.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial will cover the implementation of a news article QA app that can query the content of news articles using web data for RAG practice. This guide builds a RAG pipeline using OpenAI Chat models, Embedding, and ChromaDB vector store, utilizing Forbes News pages and Naver News pages which is the most popular news website in Korea.\n",
        "\n",
        "### 1. Pre-processing - Steps 1 to 4\n",
        "![Pre-processing](./assets/02-rag-basic-webloader-01.png)\n",
        "![](./assets/02-rag-basic-webloader-02.png)\n",
        "\n",
        "The pre-processing stage involves four steps to load, split, embed, and store documents into a Vector DB (database).\n",
        "\n",
        "- **Step 1: Document Load**: Load the document content.  \n",
        "- **Step 2: Text Split**: Split the document into chunks based on specific criteria.  \n",
        "- **Step 3: Embedding**: Generate embeddings for the chunks and prepare them for storage.  \n",
        "- **Step 4: Vector DB Storage**: Store the embedded chunks in the database.  \n",
        "\n",
        "### 2. RAG Execution (RunTime) - Steps 5 to 8\n",
        "![RAG Execution](./assets/02-rag-basic-webloader-03.png)\n",
        "![](./assets/02-rag-basic-webloader-04.png)\n",
        "- **Step 5: Retriever**: Define a retriever to fetch results from the database based on the input query. Retrievers use search algorithms and are categorized as Dense or Sparse:\n",
        "  - **Dense**: Similarity-based search.\n",
        "  - **Sparse**: Keyword-based search.\n",
        "\n",
        "- **Step 6: Prompt**: Create a prompt for executing RAG. The `context` in the prompt includes content retrieved from the document. Through prompt engineering, you can specify the format of the answer.  \n",
        "\n",
        "- **Step 7: LLM**: Define the language model (e.g., GPT-3.5, GPT-4, Claude, etc.).  \n",
        "\n",
        "- **Step 8: Chain**: Create a chain that connects the prompt, LLM, and output.  \n",
        "\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Web News Based QA(Question-Answering) Chatbot](#web-news-based-qa(question-answering)-chatbot)\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangChain Tutorial : QA with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\n",
        "- [LangChain WebLoader Tutorial](06-DocumentLoader/03-WebBaseLoader.ipynb)\n",
        "- [Naver News](https://n.news.naver.com/)\n",
        "- [Forbes](https://www.forbes.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c7aba4",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "21943adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "!pip install langchain-opentutorial\n",
        "!pip install langchain-community\n",
        "!pip install langchain-core\n",
        "!pip install langchain-openai\n",
        "!pip install langchain-chroma\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f25ec196",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"bs4\",\n",
        "        \"langchain-text-splitters\",\n",
        "        \"langchain-community\",\n",
        "        \"langchain-core\",\n",
        "        \"langchain-openai\",\n",
        "        \"langchain-chroma\",\n",
        "        \"faiss-cpu\" #if gpu is available, use faiss-gpu\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7f9065ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"RAG-Basic-WebLoader\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "690a9ae0",
      "metadata": {},
      "source": [
        "You can alternatively set API keys such as `OPENAI_API_KEY` in a `.env` file and load them.\n",
        "\n",
        "[Note] This is not necessary if you've already set the required API keys in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4f99b5b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load API keys from .env file\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95d52ce4",
      "metadata": {},
      "source": [
        "## Web News Based QA(Question-Answering) Chatbot\n",
        "\n",
        "In this tutorial we'll learn about the implementation of a news article QA app that can query the content of news articles using web data for RAG practice. This guide builds a RAG pipeline using OpenAI Chat models, Embedding, and FAISS vector store, utilizing Forbes News pages and Naver News pages which is the most popular news website in Korea.\n",
        "\n",
        "First, through the following process, we can implement a simple indexing pipeline and RAG chain with approximately 20 lines of code.\n",
        "\n",
        "**[Note]**\n",
        "- `bs4` is a library for parsing web pages.\n",
        "- `langchain` is a library that provides various AI-related functionalities. Here, we'll specifically cover text splitting (`RecursiveCharacterTextSplitter`), document loading (`WebBaseLoader`), vector storage (`Chroma`, `FAISS`), output parsing (`StrOutputParser`), and runnable passthrough (`RunnablePassthrough`).\n",
        "- Through the `langchain_openai` module, we can use OpenAI's chatbot (`ChatOpenAI`) and embedding (`OpenAIEmbeddings`) functionalities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a624a28a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cd51b8a",
      "metadata": {},
      "source": [
        "We implement a process that loads web page content, splits text into chunks for indexing, and then searches for relevant text snippets to generate new content.\n",
        "\n",
        "`WebBaseLoader` uses `bs4.SoupStrainer` to parse only the necessary parts from the specified web page.\n",
        "\n",
        "[Note]\n",
        "\n",
        "- `bs4.SoupStrainer` allows you to conveniently retrieve desired elements from the web.\n",
        "\n",
        "(Example)\n",
        "\n",
        "```python\n",
        "bs4.SoupStrainer(\n",
        "    \"div\",\n",
        "    attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "28f4c5ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents: 1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://www.forbes.com/'}, page_content='Micron To Build $7 Billion  Advanced Chip Facility In Singapore Amid AI BoomMicron Technology is investing $7 billion to build an advanced chip packaging facility in Singapore as the semiconductor giant expands its capacity to cater to booming demand for AI chips.\\r\\n\\r\\n')]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load news article content, split into chunks, and index them.\n",
        "\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://www.forbes.com/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            [\"div\", \"h2\"],\n",
        "            attrs={\"class\": [\"card--large__title\", \"card__description\"]},\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "docs = loader.load()\n",
        "print(f\"Number of documents: {len(docs)}\")\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02eb8b89",
      "metadata": {},
      "source": [
        "Similarly to the code tutorial above, you can load news articles from Naver news article pages using a similar method.\n",
        "\n",
        "<br/>\n",
        "\n",
        "```python\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://n.news.naver.com/article/437/0000378416\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            \"div\",\n",
        "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1957ac35",
      "metadata": {},
      "source": [
        "`RecursiveCharacterTextSplitter` splits documents into chunks of specified size.\n",
        "\n",
        "```python\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4aad6b84",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f9b9d02",
      "metadata": {},
      "source": [
        "Vector stores like `FAISS` or `Chroma` generate vector representations of documents based on these chunks.\n",
        "\n",
        "```python\n",
        "vectorstore = FAISS.from_documents(splits, OpenAIEmbeddings())\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "17efec71",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a vector store.\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "# Search for and generate information contained in the news.\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3585ab88",
      "metadata": {},
      "source": [
        "The retriever created through `vectorstore.as_retriever()` generates new content using the prompt fetched with `hub.pull` and the `ChatOpenAI` model.\n",
        "\n",
        "Finally, `StrOutputParser` parses the generated results into a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "975cd440",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"You are a friendly AI assistant performing Question-Answering. \n",
        "Your mission is to answer the given question based on the provided context.\n",
        "Please answer the question using the following retrieved context. \n",
        "If you cannot find the answer in the given context or if you don't know the answer, please respond with 'The information related to the question cannot be found in the provided information'.\n",
        "Please answer in English. \n",
        "However, keep technical terms and names in their original form without translation.\n",
        "\n",
        "#Question: \n",
        "{question} \n",
        "\n",
        "#Context: \n",
        "{context} \n",
        "\n",
        "#Answer:\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02147e1b",
      "metadata": {},
      "source": [
        "If you practice in Naver-News URL, you can download and input the `teddynote/rag-prompt-korean` prompt from hub. In this case, the separate prompt writing process can be skipped.\n",
        "\n",
        "```python\n",
        "prompt = hub.pull(\"teddynote/rag-prompt-korean\")\n",
        "prompt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "79d59cea",
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "\n",
        "# Create a chain.\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc434947",
      "metadata": {},
      "source": [
        "To use streaming output, use `stream_response`.\n",
        "\n",
        "```python\n",
        "stream_response = rag_chain.stream_response(\n",
        "    {\"question\": \"What is the latest news about AI?\"}\n",
        ")\n",
        "\n",
        "for chunk in stream_response:\n",
        "    print(chunk)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e7985a3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The latest news about AI is that Micron Technology is investing $7 billion to build an advanced chip packaging facility in Singapore to expand its capacity to meet the booming demand for AI chips.\n"
          ]
        }
      ],
      "source": [
        "answer = rag_chain.invoke(\"What is the latest news about AI?\")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1b3b53d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The main idea of the latest news is that Micron Technology is investing $7 billion to build an advanced chip packaging facility in Singapore to expand its capacity in response to the booming demand for AI chips.\n"
          ]
        }
      ],
      "source": [
        "answer = rag_chain.invoke(\"What is the main idea of latest news about?\")\n",
        "print(answer)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-kr-lwwSZlnu-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

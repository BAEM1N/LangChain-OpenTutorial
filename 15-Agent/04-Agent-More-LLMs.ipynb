{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "059756b7",
      "metadata": {},
      "source": [
        "# Tool Calling Agent with More LLM Models\n",
        "\n",
        "- Author: [JoonHo Kim](https://github.com/jhboyo)\n",
        "- Design: []()\n",
        "- Peer Review :\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/06-DocumentLoader/04-CSV-Loader.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/06-DocumentLoader/04-CSV-Loader.ipynb)\n",
        "\n",
        "\n",
        "## Overview\n",
        "It is not limited to `OpenAI` models but also supports implementations from diverse LLM providers such as `Anthropic`, `Google Gemini`, `Together.ai`, `Ollama`, and `Mistral`. This allows developers to leverage the unique characteristics and strengths of each model to create agents optimized for the specific requirements of their applications.\n",
        "\n",
        "Key Topics\n",
        "In this chapter, we will delve into the process of creating and executing tool-calling agents using various `LLMs`. The key topics covered include:\n",
        "\n",
        "- Tool Selection: How agents choose the most suitable tools for specific tasks.\n",
        "- `LLM` Integration: Integrating `LLMs` from `OpenAI` and other providers into LangChain to enable agent functionality.\n",
        "- Agent Creation: Creating agents using LangChain's agent classes.\n",
        "- Agent Execution: Executing agents to perform tasks.\n",
        "\n",
        "Objectives\n",
        "By the end of this chapter, you will be able to:\n",
        "\n",
        "- How to create and execute tool-calling agents using various `LLMs`.\n",
        "- Create automated workflows that call various tools using LangChain's agent classes.\n",
        "- Combine multiple `LLMs` to implement agents with optimized performance.\n",
        "\n",
        "Now, letâ€™s explore how to maximize productivity using LangChainâ€™s flexible agent framework. ðŸš€\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [List of LLMs Supporting Tool Calling](#list-of-llms-supporting-tool-calling)\n",
        "- [Using Multiple LLM Integrations with LangChain](#using-multiple-llm-integrations-with-langchain)\n",
        "- [Define the tool](#define-the-tool)\n",
        "- [Generate Prompts for Agents](#generate-prompts-for-agents)\n",
        "- [Generate an AgentExecutor, run it and review the results](#generate-an-agentexecutor-run-it-and-review-the-results)\n",
        "\n",
        "### References\n",
        "\n",
        "- [Tool Calling Agent](https://blog.langchain.dev/tool-calling-with-langchain/)\n",
        "- [LangChain ChatOpenAI](https://python.langchain.com/docs/integrations/chat/openai/)\n",
        "- [LangChain ChatAnthropic](https://python.langchain.com/docs/integrations/chat/anthropic/)\n",
        "- [LangChain ChatGoogleGenerativeAI](https://python.langchain.com/docs/integrations/providers/google/)\n",
        "- [LangChain ChatOllama](https://python.langchain.com/docs/integrations/providers/ollama/)\n",
        "- [LangChain ChatTogether](https://python.langchain.com/docs/integrations/providers/together/)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "923a83b4",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details.\n",
        "- `langchain-ollama` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8e8ad1ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -qU langchain-opentutorial\n",
        "%pip install -qU langchain-ollama==0.1.3\n",
        "%pip install -qU feedparser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "446f6eba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"ANTHROPIC_API_KEY\": \"\",\n",
        "        \"GOOGLE_API_KEY\": \"\",\n",
        "        \"OLLAMA_API_KEY\": \"\",\n",
        "        \"TOGETHER_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"Tool Calling Agent with More LLM Models\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "70361e4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langchain\",\n",
        "        \"langchain_openai\",\n",
        "        \"langchain_anthropic\",\n",
        "        \"langchain_google_genai\",\n",
        "        \"langchain_ollama\",\n",
        "        \"langchain_community\",\n",
        "        \"langchain_core\"\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5877653",
      "metadata": {},
      "source": [
        "\n",
        "## List of LLMs Supporting Tool Calling\n",
        "\n",
        "To proceed with the hands-on tutorial, the following setup steps are required:\n",
        "\n",
        "1. Issue API keys for each `LLM` call.\n",
        "2. Add the issued key to the `.env` file.\n",
        "\n",
        "\n",
        "**Anthropic**\n",
        "\n",
        "- [Anthropic API Key Issuance](https://console.anthropic.com/settings/keys)\n",
        "- Add the issued key to the `.env` file as `ANTHROPIC_API_KEY`.\n",
        "\n",
        "\n",
        "**Gemini**\n",
        "\n",
        "- [Gemini API Key Issuance](https://aistudio.google.com/app/apikey?hl=ko)\n",
        "- Add the issued key to the `.env` file as `GOOGLE_API_KEY`.\n",
        "\n",
        "\n",
        "**Ollama**\n",
        "- [List of Ollama Tool Calling Supported Models](https://ollama.com/search?c=tools)\n",
        "- Instead of issuing an API Key, [Ollama installation](https://ollama.com) is required to proceed with the ollama tutorial.\n",
        "- We will use [lama3.1 Model](https://ollama.com/library/llama3.1) for This Tutorial for this tutorial.\n",
        "- After installing Ollama, run the following commands in the terminal to download the models: `ollama pull llama3.1` and `ollama pull qwen2.5`\n",
        "\n",
        "\n",
        "**Together AI**\n",
        "- [Together API Key Issuance](https://api.together.ai/)\n",
        "- Add the issued key to the `.env` file as `TOGETHER_API_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f3e9011",
      "metadata": {},
      "source": [
        "## Using Multiple LLM Integrations with LangChain\n",
        "This walks you through integrating and configuring various `LLMs` using LangChain, allowing you to experiment with different models from providers like `OpenAI`, `Anthropic`, `Google`, and others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "265b2b64",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_ollama import ChatOllama\n",
        "import os\n",
        "\n",
        "# GPT-4o-mini\n",
        "gpt = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Claude-3-5-sonnet\n",
        "claude = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0)\n",
        "\n",
        "# Gemini-1.5-pro-latest\n",
        "gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
        "\n",
        "# Llama-3.1-70B-Instruct-Turbo\n",
        "llama = ChatOpenAI(\n",
        "    base_url=\"https://api.together.xyz/v1\",\n",
        "    api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
        "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
        ")\n",
        "\n",
        "# Llama-3.1\n",
        "ollama = ChatOllama(model=\"llama3.1\", temperature=0)\n",
        "\n",
        "# Qwen2.5 7B \n",
        "qwen = ChatOllama(\n",
        "    model=\"qwen2.5:latest\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "486960e0",
      "metadata": {},
      "source": [
        "## Define the tool\n",
        "\n",
        "Before defining the tool, we will build some functions to collect and fetch news from Website for keyword that user input.\n",
        "\n",
        " `_fetch_news` funtion gets news from given url and return the result as a list of dictionaries.\n",
        " * `Args:` url (str) is a url for fetching news. k (int) is a number of news to fetch.(default: 3)\n",
        " * `Return:` List[Dict[str, str]] is a list of dictionaries that contains news title and link.\n",
        "\n",
        "\n",
        " `_collect_news` return a sorted list of news items.\n",
        " * `Args:` news_list (List[Dict[str, str]]) is a list of dictionaries that contains news information.\n",
        " * `Return:` List[Dict[str, str]] is a list of dictionaries that contains url and contents.\n",
        "\n",
        "`search_by_keyword` funtion searches news using keyword and return the result as a list of dictionaries.\n",
        " * `Args:` keyword (str) is a keyword to search. k (int) is a number of news to fetch.(default: 3)\n",
        " * `Return:` List[Dict[str, str]] is a list of dictionaries that contains url and contents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9ea774db",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Dict, Optional\n",
        "from urllib.parse import quote\n",
        "import feedparser\n",
        "\n",
        "class GoogleNews:\n",
        "\n",
        "    def _fetch_news(self, url: str, k: int = 3) -> List[Dict[str, str]]:\n",
        "        news_data = feedparser.parse(url)\n",
        "        return [\n",
        "            {\"title\": entry.title, \"link\": entry.link}\n",
        "            for entry in news_data.entries[:k]\n",
        "        ]\n",
        "    \n",
        "    def _collect_news(self, news_list: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
        "        if not news_list:\n",
        "            print(\"There is no news for the keyword.\")\n",
        "            return []\n",
        "\n",
        "        result = []\n",
        "        for news in news_list:\n",
        "            result.append({\"url\": news[\"link\"], \"content\": news[\"title\"]})\n",
        "\n",
        "        return result\n",
        "\n",
        "    def search_by_keyword(\n",
        "            self, keyword: Optional[str] = None, k: int = 3\n",
        "        ) -> List[Dict[str, str]]:\n",
        "            \n",
        "            if keyword:\n",
        "                encoded_keyword = quote(keyword)\n",
        "                url = f\"https://news.google.com/rss/search?q={encoded_keyword}&hl=en&gl=US&ceid=US:en\"\n",
        "            else:\n",
        "                url = f\"https://news.google.com/rss?hl=en&gl=US&ceid=US:en\"\n",
        "\n",
        "            news_list = self._fetch_news(url, k)\n",
        "            return self._collect_news(news_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b482270",
      "metadata": {},
      "source": [
        "Fetch News for keyword that user input from Google News Website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b694c35",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from typing import List, Dict\n",
        "\n",
        "# Define the tool\n",
        "@tool\n",
        "def search_news(query: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"Search Google News by input keyword\"\"\"\n",
        "    news_tool = GoogleNews()\n",
        "    return news_tool.search_by_keyword(query, k=5)\n",
        "\n",
        "print(f\"Tool Name: {search_news.name}\")\n",
        "print(f\"Tool Description: {search_news.description}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d079b5b9",
      "metadata": {},
      "source": [
        "\n",
        "Define Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "da936bf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "tools = [search_news]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c5dc7d5",
      "metadata": {},
      "source": [
        "## Generate Prompts for Agents\n",
        "Prompt is a text that describes the task the model will perform.(Input the tool name and role)\n",
        "\n",
        "\n",
        "- `chat_history` : A variable that stores previous conversation history (can be omitted if multi-turn support is not required).\n",
        "- `agent_scratchpad` : A variable for temporary storage used by the agent.\n",
        "- `input` : The user's input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ea1677a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.agents import create_tool_calling_agent\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant.\"\n",
        "            \"Make sure to use the `search_news` tool for searching keyword related news.\",        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41401ee8",
      "metadata": {},
      "source": [
        "Generate an `Agent` based on an `LLM` (Large Language Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "1920a041",
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt_agent = create_tool_calling_agent(gpt, tools, prompt)\n",
        "claude_agent = create_tool_calling_agent(claude, tools, prompt)\n",
        "gemini_agent = create_tool_calling_agent(gemini, tools, prompt)\n",
        "llama_agent = create_tool_calling_agent(llama, tools, prompt)\n",
        "ollama_agent = create_tool_calling_agent(ollama, tools, prompt)\n",
        "qwen_agent = create_tool_calling_agent(qwen, tools, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e14778c",
      "metadata": {},
      "source": [
        "## Generate an AgentExecutor, run it and review the results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d8e843e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "# execute gpt_agent\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=gemini_agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        ")\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"Search the latest AI Investment news\"})\n",
        "\n",
        "print(\"Results of Agent Execution:\")\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "433c7da6",
      "metadata": {},
      "source": [
        "Run the agent using various `LLMs` (Large Language Models).\n",
        "\n",
        "The following is a function that generates and runs an Agent using the provided `LLM` and outputs the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "71ce609d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def execute_agent(llm, tools, input_text, label):\n",
        "    \n",
        "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
        "    result = executor.invoke({\"input\": input_text})\n",
        "    print(f\"Results from [{label}] \")\n",
        "\n",
        "    if isinstance(result[\"output\"], list) and len(result[\"output\"]) > 0:\n",
        "        for item in result[\"output\"]:\n",
        "            if \"text\" in item:\n",
        "                print(item[\"text\"])\n",
        "    elif isinstance(result[\"output\"], str):\n",
        "        print(result[\"output\"])\n",
        "    else:\n",
        "        print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2213e2f",
      "metadata": {},
      "source": [
        "Generate and run agents for each LLM and outputs the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "96c5c75d",
      "metadata": {},
      "outputs": [],
      "source": [
        "query = (\n",
        "    \"Search for news related to AI investment and write the results in the format of an Instagram post.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "456f8c93",
      "metadata": {},
      "outputs": [],
      "source": [
        "# gpt\n",
        "execute_agent(gpt, tools, query, \"gpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c36e6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# claude\n",
        "execute_agent(claude, tools, query, \"claude\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eddc1886",
      "metadata": {},
      "outputs": [],
      "source": [
        "# gemini\n",
        "execute_agent(gemini, tools, query, \"gemini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a58b85e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# llama3.1 70B (Together.ai)\n",
        "execute_agent(\n",
        "    llama,\n",
        "    tools,\n",
        "    \"Search AI related news and write it in Instagram post format\",\n",
        "    \"llama3.1 70B\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5acd45a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# llama3.1 8B (ollama)\n",
        "execute_agent(ollama, tools, query, \"llama3.1(Ollama)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6841a173",
      "metadata": {},
      "outputs": [],
      "source": [
        "# qwen2.5 7B (ollama)\n",
        "execute_agent(qwen, tools, query, \"qwen2.5(Ollama)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py-test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

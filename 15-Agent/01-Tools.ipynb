{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "\n",
    "\n",
    "- Author: [Jaeho Kim](https://github.com/Jae-hoya)\n",
    "- Design: []()\n",
    "- Peer Review:\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "## OverView\n",
    "\n",
    "A tool is an interface that allows agents, chains, or LLMs to interact with the external world.\n",
    "\n",
    "LangChain provides built-in tools that are easy to use, and it also enables users to easily build custom tools.\n",
    "\n",
    "**You can find the list of tools integrated into LangChain at the link below.**\n",
    "\n",
    "- [List of Tools Integrated with LangChain](https://python.langchain.com/docs/integrations/tools/)\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Built-in tools](#built-in-tools)\n",
    "- [Python REPL Tool](#python-repl-tool)\n",
    "- [Search API Tool(Tavily)](#search-api-tooltavily)\n",
    "- [Image Generation Tool (DALL-E)](#image-generation-tool-dall-e)\n",
    "- [Custom Tools](#custom-tools)\n",
    "### References\n",
    "\n",
    "- [LangChain: List of Integrated Tools](https://python.langchain.com/docs/integrations/tools/)\n",
    "- [LangChain Tools/Toolkits](https://python.langchain.com/docs/integrations/tools/)\n",
    "- [LangChain: PythonREPLTool](https://python.langchain.com/docs/integrations/tools/python/)\n",
    "- [LangChain: Tavily Search](https://python.langchain.com/docs/integrations/tools/tavily_search/)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_experimental\",\n",
    "        \"feedparser\"\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"TAVILY_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"01-Tools\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment variables have been set successfully.\n",
    "You can alternatively set API keys, such as `OPENAI_API_KEY` in a `.env` file and load them.\n",
    "\n",
    "[Note] This is not necessary if you've already set the required API keys in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load API keys from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "When using tools, warning messages may be displayed.\n",
    "\n",
    "For example, there are security warnings in the **REPL** environment.\n",
    "`PythonREPLTool` is a tool for executing Python code and can potentially execute commands (e.g., file system access, network requests) that may pose security risks.\n",
    "In such cases, LangChain or Python itself may output warning messages.\n",
    "\n",
    "To ignore these warning messages, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore warning messages.\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in tools\n",
    "\n",
    "You can use pre-defined tools and toolkits provided by LangChain.\n",
    "\n",
    "A tool refers to a single utility, while a toolkit combines multiple tools into a single unit for use.\n",
    "\n",
    "You can find the relevant tools at the link below.\n",
    "\n",
    "**Note**\n",
    "- [LangChain Tools/Toolkits](https://python.langchain.com/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python REPL Tool\n",
    "\n",
    "This tool provides a class for executing Python code in a **REPL (Read-Eval-Print Loop)** environment.\n",
    "- [PythonREPLTool](https://python.langchain.com/docs/integrations/tools/python/)\n",
    "\n",
    "**Description**\n",
    "\n",
    "- Provides a Python shell environment.\n",
    "- Executes valid Python commands as input.\n",
    "- Use the `print(...)` function to view results.\n",
    "\n",
    "**Key Features**\n",
    "\n",
    "- sanitize_input: Option to sanitize input (default: True)\n",
    "- python_repl: Instance of **PythonREPL** (default: executed in the global scope)\n",
    "\n",
    "**Usage**\n",
    "\n",
    "- Create an instance of `PythonREPLTool `.\n",
    "- Execute Python code using the `run` , `arun` , or `invoke` methods.\n",
    "\n",
    "**Input Sanitization**\n",
    "\n",
    "- Removes unnecessary spaces, backticks, the keyword \"python,\" and other extraneous elements from the input string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "# Creates a tool for executing Python code.\n",
    "python_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executes Python code and returns the results.\n",
    "print(python_tool.invoke(\"print(100 + 200)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of requesting an LLM to write Python code and returning the results.\n",
    "\n",
    "**Workflow Summary**\n",
    "1. Request the LLM model to write Python code for a specific task.\n",
    "2. Execute the generated code to obtain the results.\n",
    "3. Output the results.\n",
    "\n",
    "**Note**\n",
    "\n",
    "I recommend using a model equivalent to or higher than GPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "# A function that executes Python code, outputs intermediate steps, and returns the tool execution results.\n",
    "def print_and_execute(code, debug=True):\n",
    "    if debug:\n",
    "        print(\"CODE:\")\n",
    "        print(code)\n",
    "    return python_tool.invoke(code)\n",
    "\n",
    "\n",
    "# A prompt requesting Python code to be written.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are Raymond Hetting, an expert python programmer, well versed in meta-programming and elegant, concise and short but well documented code. You follow the PEP8 style guide. \"\n",
    "            \"Return only the code, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the code.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "# Create LLM model.\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Create a chain using the prompt and the LLM model.\n",
    "chain = prompt | llm | StrOutputParser() | RunnableLambda(print_and_execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE:\n",
      "import random\n",
      "\n",
      "def generate_powerball():\n",
      "    main_numbers = sorted(random.sample(range(1, 70), 5))\n",
      "    powerball = random.randint(1, 26)\n",
      "    return main_numbers, powerball\n",
      "\n",
      "print(generate_powerball())\n",
      "([23, 27, 32, 34, 58], 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Outputting the results.\n",
    "print(chain.invoke(\"Write code to generate Powerball numbers.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search API Tool(Tavily)\n",
    "\n",
    "This is a tool that implements a search function using the `Tavily` Search API. It provides two main classes: `TavilySearchResults` and `TavilyAnswer` .\n",
    "\n",
    "**API Key Issuance URL**\n",
    "- https://app.tavily.com/\n",
    "\n",
    "Set the issued API key as an environment variable.\n",
    "\n",
    "For example, configure the .env file as follows:\n",
    "\n",
    "```\n",
    "TAVILY_API_KEY=tvly-abcdefghijklmnopqrstuvwxyz\n",
    "```\n",
    "\n",
    "### TavilySearchResults\n",
    "\n",
    "**Description**\n",
    "- Queries the Tavily Search API and returns results in JSON format.\n",
    "- A search engine optimized for comprehensive, accurate, and reliable results.\n",
    "- Useful for answering questions about current events.\n",
    "\n",
    "**Key Parameters**\n",
    "- `max_results` (int): Maximum number of search results to return (default: 5).\n",
    "- `search_depth` (str): Search depth (\"basic\" or \"advanced\").\n",
    "- `include_domains` (List[str]): List of domains to include in search results.\n",
    "- `exclude_domains` (List[str]): List of domains to exclude from search results.\n",
    "- `include_answer` (bool): Whether to include a short answer to the original query.\n",
    "- `include_raw_content` (bool): Whether to include refined HTML content from each site.\n",
    "- `include_images` (bool): Whether to include a list of images related to the query.\n",
    "\n",
    "**Return Value**\n",
    "- A JSON-formatted string containing the search results (url, content)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Create tool.\n",
    "tool = TavilySearchResults(\n",
    "    max_results=6,\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    # include_images=True,\n",
    "    # search_depth=\"advanced\", # or \"basic\"\n",
    "    include_domains=[\"github.io\"],\n",
    "    # exclude_domains = []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://stonefishy.github.io/2024/11/12/introduction-to-langchain-make-ai-smarter-and-easy-to-use/',\n",
       "  'content': 'What is LangChain? LangChain is a tool for developers that helps them build applications using large language models (LLMs)—the same kind of AI that powers chatbots, writing assistants, and more. LLMs can understand and generate text in a way that sounds like a real person. However, using these models to make powerful apps can be complicated.'},\n",
       " {'url': 'https://kirenz.github.io/lab-langchain-functions/slides/06_functional_conversation.html',\n",
       "  'content': \"LangChain helps developers leverage the power of language models in their applications. Finished chain. {'input': 'what is langchain?', 'output': 'LangChain is a framework designed to simplify the creation of applications using large language models (LLMs).\"},\n",
       " {'url': 'https://aws-samples.github.io/amazon-bedrock-samples/agents-and-function-calling/open-source-agents/langgraph/langgraph-single-agent/',\n",
       "  'content': 'The tool will use the local csv file to retrieve historical data about travel destinations. It will then analyze the data and return the most popular destination for the user. We will use LangChain Tools to create tools that are used by our agents.'},\n",
       " {'url': 'https://aws-samples.github.io/amazon-bedrock-samples/agents-and-function-calling/open-source-agents/langgraph/langgraph-agents-multimodal/',\n",
       "  'content': 'The tool will use the local csv file to retrieve historical data about travel destinations. It will then analyze the data and return the most popular destination for the user. We will use LangChain Tools to create tools that are used by our agents.'},\n",
       " {'url': 'https://kirenz.github.io/lab-langchain-functions/slides/05_tools_routing.html',\n",
       "  'content': 'Langchain Functions - Tools and Routing from langchain.agents import tool from langchain.tools.render import format_tool_to_openai_function format_tool_to_openai_function(get_current_temperature) {‘name’: ‘get_current_temperature’, ‘description’: ‘get_current_temperature(latitude: float, longitude: float) -> dict - Fetch current temperature for given coordinates.’, ‘parameters’: {‘title’: ‘OpenMeteoInput’, ‘type’: ‘object’, ‘properties’: {‘latitude’: {‘title’: ‘Latitude’, ‘description’: ‘Latitude of the location to fetch weather data for’, ‘type’: ‘number’}, ‘longitude’: {‘title’: ‘Longitude’, ‘description’: ‘Longitude of the location to fetch weather data for’, ‘type’: ‘number’}}, ‘required’: [‘latitude’, ‘longitude’]}} {‘name’: ‘search_wikipedia’, ‘description’: ‘search_wikipedia(query: str) -> str - Run Wikipedia search and get page summaries.’, ‘parameters’: {‘title’: ‘search_wikipediaSchemaSchema’, ‘type’: ‘object’, ‘properties’: {‘query’: {‘title’: ‘Query’, ‘type’: ‘string’}}, ‘required’: [‘query’]}} format_tool_to_openai_function(search_wikipedia) search_wikipedia, get_current_temperature result = chain.invoke({\"input\": \"what is the weather in stuttgart right now\"}) result.tool_input get_current_temperature(result.tool_input) result = chain.invoke({\"input\": \"What is the weather in stuttgart right now?\"}) result = chain.invoke({\"input\": \"What is langchain?\"})'},\n",
       " {'url': 'https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/agents.html',\n",
       "  'content': 'Langchain Tools# In addition to custom tools, you can also use tools from the Langchain library by wrapping them in LangChainToolAdapter. import pandas as pd from autogen_ext.tools.langchain import LangChainToolAdapter from langchain_experimental.tools.python.tool import PythonAstREPLTool df = pd. read_csv'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute tool.\n",
    "tool.invoke({\"query\": \"What is Langchain Tools?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Generation Tool (DALL-E)\n",
    "\n",
    "- `DallEAPIWrapper Class` : A wrapper for OpenAI's DALL-E image generator.\n",
    "\n",
    "This tool allows easy integration of the DALL-E API to implement text-based image generation functionality. With various configuration options, it can be utilized as a flexible and powerful image generation tool.\n",
    "\n",
    "**Key Properties**\n",
    "\n",
    "- `model` : The name of the DALL-E model to use ( **dall-e-2**, **dall-e-3** ).\n",
    "\n",
    "- `n` : Number of images to generate (default: 1).\n",
    "\n",
    "- `size` : Size of the generated image:\n",
    "  - \"dall-e-2\": \"1024x1024\", \"512x512\", \"256x256\"\n",
    "  - \"dall-e-3\": \"1024x1024\", \"1792x1024\", \"1024x1792\"\n",
    "\n",
    "- `style` : Style of the generated image ( **natural** , **vivid** ).\n",
    "\n",
    "- `quality` : Quality of the generated image ( **standard**, **hd** ).\n",
    "\n",
    "- `max_retries` : Maximum number of retries for generation.\n",
    "\n",
    "**Key Features**\n",
    "- Generates images based on text descriptions using the DALL-E API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow Summary**\n",
    "\n",
    "The following is an example of generating images using the `DALL-E` Image Generator.\n",
    "\n",
    "This time, we will use the `DallEAPIWrapper` to generate images.\n",
    "\n",
    "The input prompt will request the LLM model to write a prompt for generating images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a Neo-Classical painting that humorously depicts a group of elegantly dressed individuals in a grand, classical setting, all intently staring at their smartphones instead of engaging with each other. The scene should feature opulent architecture, with marble columns, intricate frescoes, and lush drapery in the background. Characters should embody the fashion and demeanor of the Neo-Classical era: men in tailored coats with waistcoats and women in flowing gowns with empire waistlines. Their expressions should range from confusion to fascination as they interact with their devices. Include subtle anachronistic elements, like modern technology blending with classical motifs—perhaps a smartphone adorned with gold leaf or digital notifications emerging from a classic scroll. Capture the irony of the situation with a slightly exaggerated, satirical tone, and ensure the color palette is rich and vibrant, reflecting the artistry of the Neo-Classical period.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the ChatOpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9, max_tokens=1000)\n",
    "\n",
    "# Define a prompt template for DALL-E image generation\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. \"\n",
    "    \"Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt\"\n",
    "    \"Output should be less than 1000 characters. Write in English only.\"\n",
    "    \"Image Description: \\n{image_desc}\",\n",
    ")\n",
    "\n",
    "# Create a chain connecting the prompt, LLM, and output parser\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Execute the chain\n",
    "image_prompt = chain.invoke(\n",
    "    {\"image_desc\": \"A Neo-Classicism painting satirizing people looking at their smartphones.\"}\n",
    ")\n",
    "\n",
    "# Output the image prompt\n",
    "print(image_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s use the previously generated image prompt as input to the `DallEAPIWrapper` to generate an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-cklzgJgdr1X4aNqRAAPddNfR/user-UJN3VEkv67JiO9Mm1aeNBkBJ/img-56VdSxrOtnRtyTVolBLzWzty.png?st=2025-01-15T06%3A06%3A02Z&se=2025-01-15T08%3A06%3A02Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-01-15T00%3A27%3A31Z&ske=2025-01-16T00%3A27%3A31Z&sks=b&skv=2024-08-04&sig=L8Z4kTwlqm42cZH3Sw%2BhRTE4r60MBYkA2IAn9Q2L0F8%3D\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the DALL-E API Wrapper\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from IPython.display import Image\n",
    "\n",
    "dalle = DallEAPIWrapper(\n",
    "    model=\"dall-e-3\",\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "# query\n",
    "query = \"A Neo-Classicism painting satirizing people looking at their smartphones.\"\n",
    "\n",
    "\n",
    "# Generate image and retrieve URL\n",
    "# Use chain.invoke() to convert the image description into a DALL-E prompt\n",
    "# Use dalle.run() to generate the actual image\n",
    "image_url = dalle.run(chain.invoke({\"image_desc\": query}))\n",
    "\n",
    "# Display the generated image.\n",
    "Image(url=image_url, width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Tools\n",
    "\n",
    "In addition to the built-in tools provided by LangChain, you can define and use your own custom tools.\n",
    "\n",
    "To do this, use the `@tool` decorator provided by the `langchain.tools` module to convert a function into a tool.\n",
    "\n",
    "### @tool Decorator\n",
    "\n",
    "This decorator allows you to transform a function into a tool. It provides various options to customize the behavior of the tool.\n",
    "\n",
    "**How to Use**\n",
    "1. Apply the `@tool` decorator above the function.\n",
    "2. Set the decorator parameters as needed.\n",
    "\n",
    "Using this decorator, you can easily convert regular Python functions into powerful tools, enabling automated documentation and flexible interface creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# Convert a function into a tool using a decorator.\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute tool.\n",
    "add_numbers.invoke({\"a\": 3, \"b\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute tool.\n",
    "multiply_numbers.invoke({\"a\": 3, \"b\": 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom Tool for Google News Article Search\n",
    "\n",
    "Define the `GoogleNews` class, which will be used as a tool to search for Google News articles.\n",
    "\n",
    "**Note**\n",
    "- No API key is required (because it uses RSS feeds).\n",
    "\n",
    "This tool searches for news articles provided by **news.google.com** .\n",
    "\n",
    "**Description**\n",
    "- Uses the Google News search API to retrieve the latest news.\n",
    "- Allows searching for news based on keywords.\n",
    "\n",
    "**Key Parameters**\n",
    "- `k` (int): Maximum number of search results to return (default: 5).\n",
    "\n",
    "```python\n",
    "# hl: Language, gl: Region, ceid: Region and Language Code\n",
    "url = f\"{self.base_url}?hl=en&gl=US&ceid=US:en\" \n",
    "```\n",
    "\n",
    "In the code, you can adjust the search results' language and region by modifying the language (hl), region (gl), and region and language code (ceid).\n",
    "\n",
    "**Note**\n",
    "\n",
    "Save the provided code as `google_news.py` , and then you can import it in other files using `from google_news import GoogleNews` .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from urllib.parse import quote\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "class GoogleNews:\n",
    "    \"\"\"\n",
    "    This is a class for searching Google News and returning the results.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the GoogleNews class.\n",
    "        Sets the base_url attribute.\n",
    "        \"\"\"\n",
    "        self.base_url = \"https://news.google.com/rss\"\n",
    "\n",
    "    def _fetch_news(self, url: str, k: int = 3) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Fetches news from the given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL to fetch the news from.\n",
    "            k (int): The maximum number of news articles to fetch (default: 3).\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: A list of dictionaries containing news titles and links.\n",
    "        \"\"\"\n",
    "        news_data = feedparser.parse(url)\n",
    "        return [\n",
    "            {\"title\": entry.title, \"link\": entry.link}\n",
    "            for entry in news_data.entries[:k]\n",
    "        ]\n",
    "\n",
    "    def _collect_news(self, news_list: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Formats and returns the list of news articles.\n",
    "\n",
    "        Args:\n",
    "            news_list (List[Dict[str, str]]): A list of dictionaries containing news information.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: A list of dictionaries containing URLs and content.\n",
    "        \"\"\"\n",
    "        if not news_list:\n",
    "            print(\"No news available for the given keyword.\")\n",
    "            return []\n",
    "\n",
    "        result = []\n",
    "        for news in news_list:\n",
    "            result.append({\"url\": news[\"link\"], \"content\": news[\"title\"]})\n",
    "\n",
    "        return result\n",
    "\n",
    "    def search_latest(self, k: int = 3) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Searches for the latest news.\n",
    "\n",
    "        Args:\n",
    "            k (int): The maximum number of news articles to search for (default: 3).\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: A list of dictionaries containing URLs and content.\n",
    "        \"\"\"\n",
    "        #url = f\"{self.base_url}?hl=ko&gl=KR&ceid=KR:ko\"\n",
    "        url = f\"{self.base_url}?hl=en&gl=US&ceid=US:en\" # hl: 언어, gl: 지역, ceid: 지역 및 언어 코드\n",
    "        news_list = self._fetch_news(url, k)\n",
    "        return self._collect_news(news_list)\n",
    "\n",
    "    def search_by_keyword(\n",
    "        self, keyword: Optional[str] = None, k: int = 3\n",
    "    ) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Searches for news using a keyword.  \n",
    "\n",
    "        Args:\n",
    "            keyword (Optional[str]): The keyword to search for (default: None).\n",
    "            k (int): The maximum number of news articles to search for (default: 3).\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: A list of dictionaries containing URLs and content.\n",
    "        \"\"\"\n",
    "        if keyword:\n",
    "            encoded_keyword = quote(keyword)\n",
    "            url = f\"{self.base_url}/search?q={encoded_keyword}&hl=en&gl=US&ceid=US:en\"\n",
    "        else:\n",
    "            url = f\"{self.base_url}?hl=en&gl=US&ceid=US:en\"\n",
    "        news_list = self._fetch_news(url, k)\n",
    "        return self._collect_news(news_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_tool = GoogleNews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://news.google.com/rss/articles/CBMimAFBVV95cUxNaThyMnBjNjJpQjlQQTcwQjdoTEZPc1plbDdYU29YWlNVakE1NzVkV2ZNZHRyYlFSSjg1VDRNX2ZPT1NZdkM0ckVxMmxwaW1PbTdpay1EX2lUbFNqblIxOXdUZ3VDTVZoVmRlWVZXLTBUNG5SSUJZa3RieEFST0VjQ1hSRkxWNzRXSlBYb3k3QzEzUGdtNHo2dg?oc=5',\n",
       "  'content': \"A Once-in-a-Decade Investment Opportunity: 1 Artificial Intelligence (AI) Semiconductor Stock to Buy Hand Over Fist and Hold for the Next 10 Years (Hint: It's Not Nvidia) - The Motley Fool\"},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMixAFBVV95cUxNZmZLZHlKQXZCZllQTTNTcEt4Vy1GZDhXNFdlbnZURXY3UzJCTWNneDZja1pwa003LW45V2NFcjR1RzZOdk5PcnBUV3ZsemV2eTlHZUlMdXJHTHBsNzBVaHJwRmNIR0JtQzhaNU1IODE5WlJKZk5HV0xxVThUZjhma2JnbUFVUEktRFRxcFNrS1B0WDV4ZTZTdzVIQWVCakwzM1VUd0NhaGozZlVod2NkZW5qay1QWEgxcnpNT2lkNGRoN1Jy0gHKAUFVX3lxTE5TS2I1RjRmYi1nUDFNQU9jckRxLWdPRC1kbUxuUVQ5dnFLQWN3OW5zdXRQOW5xZmtSeHZ1UTdNN1ZWMUdrSGdQU0ZtV0lFM2lfZjhyWk8wSHVmVmpqVGtUSXo1TDh4R3dmWnpBSFhEMjI1WklGa1BMc3VnTWgtUEc5NlkyTUZqZ3M0V3o3YmwzX3dqVDk5clU5dTFOOFZBS2dJUjVPMG1BWVpfM1d1aDg2MU9VX0M2aC0wSW1EYXZhdWN4RnNEMkFQRWc?oc=5',\n",
       "  'content': 'Invest in self-driving cars, AI and robotics — and avoid crypto except bitcoin - MarketWatch'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMidEFVX3lxTE9qSUQ2M0ZndUYtYVljelpvbEdpaVNFR0NfeE54NUpJbEZuekRNOGp4b0dsVnBJSU05bHdEMWhRcGh3Wl9IdUZ6U1MzVnBOaU9pSmVfQ09FSzAxaEhTUGtWTU9FWFpTVjNxNWw0Mzd1NXFuRVZ5?oc=5',\n",
       "  'content': \"Here's My Top AI ETF to Buy Right Now - Yahoo Finance\"}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_tool.search_by_keyword(\"AI Investment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# Create a tool for searching news by keyword\n",
    "@tool\n",
    "def search_keyword(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Look up news by keyword\"\"\"\n",
    "    print(query)\n",
    "    news_tool = GoogleNews()\n",
    "    return news_tool.search_by_keyword(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain AI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://news.google.com/rss/articles/CBMib0FVX3lxTE9qeUFQd08yN3pXenFYeWRTM1dHN3ZtTGVvaDAzREVNRU02ZVhNRFZCWmFpRm9obTN5QXF1TlpaYUI3d2VJYTBNeHNyUGJ3MXdVQWNDVW5MTVk4UDlfazFfX1hRRWpUeHBfUGRfS0pBdw?oc=5',\n",
       "  'content': 'Vulnerabilities in LangChain Gen AI - Unit 42'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMixgFBVV95cUxNUzhFZEtsS2FrNTZ1ejVDejBQRThtSDA5TUtMbWRHOUxfUEtBVl8teERpZXp5U2wzbktZeWdTWnhKc2V4RnM2SXc0TzBsNVlQMktqUXRwNDliQW9yaTVnT3lzZ0lxeThobTliUEJRd05VM3V1anJ3bUh4cGJRbk44a1V0MVMzSEZfc2c4am04QnJBM2ZhZThTQ1NvYlhQUVBZbmhJWVZQdzlWWjE0UVdQRjYtWU1iSWl6WFBBTXdsQ2ROSHUxWmc?oc=5',\n",
       "  'content': 'LangChain Meets Home Assistant: Unlock the Power of Generative AI in Your Smart Home - Towards Data Science'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMi6wFBVV95cUxPNEtmajI2MWxEb2FRSUNLWkhBQmV5VThPUVllNkRzbGEwOW1mRDZVZEhxYnI3X3BxZUZ1WThGbmF6WUV6MnVSaDJtN0ZUd2VZdGt5NV9CNHJRVXllVElnZE5DaVJDdFBSZHU5aGI3XzM3RTR1YVdyU19pYjJER2NTM080dlYyVjd6MDNFOTFudm5WRG1zdk9WNUxJTVpoakxEWlZxR3RaSmZiQ2FOdVA4YnFjUXBjeDdaRzNxNzVzbEU1ak9RSkY1bVVIRGFrdFBfNEhkcVhJNS0xdFFDY1IyMXBNSEUxZlJQeGlF?oc=5',\n",
       "  'content': 'Create a next generation chat assistant with Amazon Bedrock, Amazon Connect, Amazon Lex, LangChain, and WhatsApp - AWS Blog'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMitgFBVV95cUxNSmpOTkdfRFl4WlBqWTdHLWRGajllZVdMZklQaE5mRVNfc1lYLU9vZHNHWlZ0SFJET1ljVzcxVWRDQWRxMnQ3MnBlc0w3RnFlajIwdnk1a0tya05tQTRhOVN2UExLUy1YNEE1U3Jwa3F0YU1hT1kxRHlqYmU0SWpyNW94WXFtSC1zNVh3WkxZWkdWZ0tKX3ZwdTdqeVZrVDBTMG5KQUhia2hXZkY3NmxfMmk5RDlZdw?oc=5',\n",
       "  'content': \"Google Case Study: Five Sigma's Clive Redefines Claims Management with LangChain and Vertex AI - Coverager\"},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMihAFBVV95cUxNM0YyOV96Q1JQQWpiU1FpcnlhU3VwQV83a3lOS1RsZ2VQdGRHSXE2UHExc2paNzFmVXJjWlNKLVVwaW0tc2l1S3A0OXdsY29ORENKdGw3MTNBQVRBTjgzcDFlRm12amZ2RTBKaWtaS293bEhrRjhxQXdrbzc5ZzYzRGFBVlU?oc=5',\n",
       "  'content': 'Using LangChain Tools to Build an AI Agent - IBM'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execution Results\n",
    "search_keyword.invoke({\"query\": \"LangChain AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

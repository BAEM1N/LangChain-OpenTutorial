{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96a9939",
   "metadata": {},
   "source": [
    "# MultiVectorRetriever\n",
    "\n",
    "- Author: [YooKyung Jeon](https://github.com/sirena1)\n",
    "- Peer Review: [choincnp](https://github.com/choincnp), [Hye-yoonJeong](https://github.com/Hye-yoonJeong)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/99-TEMPLATE/00-BASE-TEMPLATE-EXAMPLE.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/99-TEMPLATE/00-BASE-TEMPLATE-EXAMPLE.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "In LangChain, there's a special feature called `MultiVectorRetriever` that enables efficient querying of documents in various contexts. This feature allows documents to be stored and managed with multiple vectors, significantly enhancing the accuracy and efficiency of information retrieval.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Methods for Generating Multiple Vectors Per Document](#methods-for-generating-multiple-vectors-per-document)\n",
    "- [Document Used for Practice](#document-used-for-practice)\n",
    "- [Chunk + Original Document Retrieval](#chunk--original-document-retrieval)\n",
    "- [Storing summaries in vector storage](#storing-summaries-in-vector-storage)\n",
    "- [Utilizing Hypothetical Queries to explore document content](#utilizing-hypothetical-queries-to-explore-document-content)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Software Policy Research Institute (SPRi) - December 2023 Issue](https://spri.kr/posts/view/23669)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37cf0d8",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f4952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29876d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langchain_community\",\n",
    "        \"langchain\",\n",
    "        \"langchain_chroma\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_text_splitters\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ec0472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c356c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"09-FewShot-Prompt-Templates\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e949f426",
   "metadata": {},
   "source": [
    "## Methods for Generating Multiple Vectors Per Document\n",
    "\n",
    "1. **Creating Small Chunks**: Divide the document into smaller chunks and generate separate embeddings for each chunk. This method enables a more granular focus on specific parts of the document. It can be implemented using the `ParentDocumentRetriever`, making it easier to explore detailed information.\n",
    "\n",
    "2. **Summary Embeddings**: Generate a summary for each document and create embeddings based on this summary. Summary embeddings are particularly useful for quickly grasping the core content of a document. By focusing only on the summary instead of analyzing the entire document, efficiency can be significantly improved.\n",
    "\n",
    "3. **Utilizing Hypothetical Questions**: Create relevant hypothetical questions for each document and generate embeddings based on these questions. This approach is helpful when deeper exploration of specific topics or content is needed. Hypothetical questions enable a broader perspective on the document's content, facilitating a more comprehensive understanding.\n",
    "\n",
    "4. **Manual Addition**: Users can manually add specific questions or queries that should be considered during document retrieval. This method provides users with more control over the search process, allowing for customized searches tailored to their specific needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb6306c",
   "metadata": {},
   "source": [
    "## Document Used for Practice\n",
    "\n",
    "Software Policy Research Institute (SPRi) - December 2023 Issue\n",
    "\n",
    "- Authors: Jaeheung Yoo (Senior Researcher, AI Policy Research Division), Jisoo Lee (Research Fellow, AI Policy Research Division)\n",
    "- Link: https://spri.kr/posts/view/23669\n",
    "- File Name: `SPRI_AI_Brief_2023년12월호_F.pdf`\n",
    "\n",
    "**Note**: Download the file into the `data` folder for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b574ec5",
   "metadata": {},
   "source": [
    "The preprocessing process involves loading data from a text file and splitting the loaded documents into specified sizes.\n",
    "\n",
    "The split documents can later be used for tasks such as vectorization and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6c52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453afd1e",
   "metadata": {},
   "source": [
    "The original documents loaded from the data are stored in the docs variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a50910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제  \n",
      "2. 기업/산업 \n",
      "3. 기술/연구 \n",
      " 4. 인력/교육\n",
      "영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언\n",
      "n 영국 블레츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전 보장을 \n",
      "위한 협력 방안을 담은 블레츨리 선언을 발표\n",
      "n 첨단 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 합의했으며, \n",
      "영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정 \n",
      "KEY Contents\n",
      "£ AI 안전성 정상회의 참가국들, 블레츨리 선언 통해 AI 안전 보장을 위한 협력에 합의\n",
      "n 2023년 11월 1~2일 영국 블레츨리 파크에서 열린 AI 안전성 정상회의(AI Safety Summit)에 \n",
      "참가한 28개국 대표들이 AI 위험 관리를 위한 ‘블레츨리 선언’을 발표 \n",
      "∙선언은 AI 안전 보장을 위해 국가, 국제기구, 기업, 시민사회, 학계를 포함한 모든 이해관계자의 협력이 \n",
      "중요하다고 강조했으며,\n"
     ]
    }
   ],
   "source": [
    "print(docs[5].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ef408",
   "metadata": {},
   "source": [
    "## Chunk + Original Document Retrieval\n",
    "\n",
    "When searching through large volumes of information, embedding data into smaller chunks can be highly beneficial.\n",
    "\n",
    "With `MultiVectorRetriever`, documents can be stored and managed as multiple vectors.\n",
    "\n",
    "- The original documents are stored in the `docstore`.\n",
    "- The embedded documents are stored in the `vectorstore`.\n",
    "\n",
    "This allows for splitting documents into smaller units, enabling more accurate searches. Additionally, the contents of the original document can be accessed when needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404582fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['09bd23c4-43fc-460c-930d-a1c67a887444', '7d575c47-aff1-4033-9c6b-cb4538d820e9']\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "# Vector store for indexing child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"small_bigger_chunks\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-ada-002\"),\n",
    ")\n",
    "\n",
    "# Storage layer for parent documents\n",
    "store = InMemoryByteStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Retriever (initially empty)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# Generate document IDs\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# Verify two of the generated IDs\n",
    "print(doc_ids[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80961f",
   "metadata": {},
   "source": [
    "Defining `parent_text_splitter` for Larger Chunks and `child_text_splitter` for Smaller Chunks\n",
    "\n",
    "Here, we define `parent_text_splitter` for splitting into larger chunks and `child_text_splitter` for splitting into smaller chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc95363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RecursiveCharacterTextSplitter object for larger chunks\n",
    "parent_text_splitter = RecursiveCharacterTextSplitter(chunk_size=600)\n",
    "\n",
    "# Splitter to be used for generating smaller chunks\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e48a98",
   "metadata": {},
   "source": [
    "Create Parent documents as larger chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4437c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_docs = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    # Retrieve the ID of the current document\n",
    "    _id = doc_ids[i]\n",
    "    # Split the current document into smaller parent documents\n",
    "    parent_doc = parent_text_splitter.split_documents([doc])\n",
    "\n",
    "    for _doc in parent_doc:\n",
    "        # Store the document ID in the metadata\n",
    "        _doc.metadata[id_key] = _id\n",
    "    parent_docs.extend(parent_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5b0e5",
   "metadata": {},
   "source": [
    "Verify the `doc_id` assigned to `parent_docs`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d7ff8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '.\\\\data\\\\SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_path': '.\\\\data\\\\SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 23,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '',\n",
       " 'author': 'dj',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'Hwp 2018 10.0.0.13462',\n",
       " 'producer': 'Hancom PDF 1.3.0.542',\n",
       " 'creationDate': \"D:20231208132838+09'00'\",\n",
       " 'modDate': \"D:20231208132838+09'00'\",\n",
       " 'trapped': '',\n",
       " 'doc_id': '09bd23c4-43fc-460c-930d-a1c67a887444'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the metadata of the generated Parent documents.\n",
    "parent_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f680da0",
   "metadata": {},
   "source": [
    "Create Child documents as relatively smaller chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e56afe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_docs = []\n",
    "for i, doc in enumerate(docs):\n",
    "    # Retrieve the ID of the current document\n",
    "    _id = doc_ids[i]\n",
    "    # Split the current document into child documents\n",
    "    child_doc = child_text_splitter.split_documents([doc])\n",
    "    for _doc in child_doc:\n",
    "        # Store the document ID in the metadata\n",
    "        _doc.metadata[id_key] = _id\n",
    "    child_docs.extend(child_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe5cb5",
   "metadata": {},
   "source": [
    "Verify the `doc_id` assigned to `child_docs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80857992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '.\\\\data\\\\SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_path': '.\\\\data\\\\SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 23,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '',\n",
       " 'author': 'dj',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'Hwp 2018 10.0.0.13462',\n",
       " 'producer': 'Hancom PDF 1.3.0.542',\n",
       " 'creationDate': \"D:20231208132838+09'00'\",\n",
       " 'modDate': \"D:20231208132838+09'00'\",\n",
       " 'trapped': '',\n",
       " 'doc_id': '09bd23c4-43fc-460c-930d-a1c67a887444'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the metadata of the generated Child documents.\n",
    "child_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a346a79",
   "metadata": {},
   "source": [
    "Check the number of chunks for each split document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dfd9565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split parent_docs: 74\n",
      "Number of split child_docs: 442\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of split parent_docs: {len(parent_docs)}\")\n",
    "print(f\"Number of split child_docs: {len(child_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6ab64",
   "metadata": {},
   "source": [
    "Add the newly created smaller child document set to the vector store\n",
    "\n",
    "Next, map the parent documents to the generated UUIDs and add them to the `docstore`.\n",
    "\n",
    "- Use the `mset()` method to store document IDs and their content as key-value pairs in the document store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a291a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add both parent and child documents to the vector store\n",
    "retriever.vectorstore.add_documents(parent_docs)\n",
    "retriever.vectorstore.add_documents(child_docs)\n",
    "\n",
    "# Store the original documents in the docstore\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a644c1",
   "metadata": {},
   "source": [
    "Perform Similarity Search and Display the Most Similar Document Chunk\n",
    "\n",
    "Use the `retriever.vectorstore.similarity_search` method to search within child and parent document chunks.\n",
    "\n",
    "The first document chunk with the highest similarity will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0d9ba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of retrieved documents: 4\n"
     ]
    }
   ],
   "source": [
    "# Perform similarity search on the vectorstore\n",
    "relevant_chunks = retriever.vectorstore.similarity_search(\n",
    "    \"What is the name of the generative AI created by Samsung Electronics?\"\n",
    ")\n",
    "print(f\"Number of retrieved documents: {len(relevant_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5eb7fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10\n",
      "   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in relevant_chunks:\n",
    "    print(chunk.page_content, end=\"\\n\\n\")\n",
    "    print(\">\" * 100, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f6f1a",
   "metadata": {},
   "source": [
    "Execute a Query Using the `retriever.invoke()` Method\n",
    "\n",
    "The `retriever.invoke()` method performs a search across the full content of the original documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a29f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of retrieved documents: 2\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
      "처리를 지원\n",
      "∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = retriever.invoke(\n",
    "    \"What is the name of the generative AI created by Samsung Electronics?\"\n",
    ")\n",
    "print(f\"Number of retrieved documents: {len(relevant_docs)}\", end=\"\\n\\n\")\n",
    "print(\"=\" * 100, end=\"\\n\\n\")\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc30896",
   "metadata": {},
   "source": [
    "The default search type performed by the retriever in the vector database is similarity search.\n",
    "\n",
    "LangChain Vector Stores also support searching using [Max Marginal Relevance](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.max_marginal_relevance_search). \n",
    "\n",
    "If you want to use this method instead, you can configure the `search_type` property as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac718689",
   "metadata": {},
   "source": [
    "- Set the `search_type` property of the `retriever` object to `SearchType.mmr`.\n",
    "  - This specifies that the MMR (Maximal Marginal Relevance) algorithm should be used during the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c545fc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
      "처리를 지원\n",
      "∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# Set the search type to Maximal Marginal Relevance (MMR)\n",
    "retriever.search_type = SearchType.mmr\n",
    "\n",
    "# Search all related documents\n",
    "print(\n",
    "    retriever.invoke(\n",
    "        \"What is the name of the generative AI created by Samsung Electronics?\"\n",
    "    )[0].page_content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07d08019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
      "처리를 지원\n",
      "∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# Set search type to similarity_score_threshold\n",
    "retriever.search_type = SearchType.similarity_score_threshold\n",
    "retriever.search_kwargs = {\"score_threshold\": 0.3}\n",
    "\n",
    "# Search all related documents\n",
    "print(\n",
    "    retriever.invoke(\n",
    "        \"What is the name of the generative AI created by Samsung Electronics?\"\n",
    "    )[0].page_content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d203555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# Set search type to similarity and k value to 1\n",
    "retriever.search_type = SearchType.similarity\n",
    "retriever.search_kwargs = {\"k\": 1}\n",
    "\n",
    "# Search all related documents\n",
    "print(\n",
    "    len(\n",
    "        retriever.invoke(\n",
    "            \"What is the name of the generative AI created by Samsung Electronics?\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d961b6c",
   "metadata": {},
   "source": [
    "## Storing summaries in vector storage\n",
    "\n",
    "Summaries can often provide a more accurate extraction of the contents of a chunk, which can lead to better search results.\n",
    "\n",
    "This section describes how to generate summaries and how to embed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7c44d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split documents: 61\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries for loading PDF files and splitting text\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the PDF file loader\n",
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# Split text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=50)\n",
    "\n",
    "# Load a PDF file and run Text Split\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# Output the number of split documents\n",
    "print(f\"Number of split documents: {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a161ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "summary_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # Create a prompt template for document summaries\n",
    "    | ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an expert in summarizing documents in Korean.\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Summarize the following documents in 3 sentences in bullet points format.\\n\\n{doc}\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    # Using OpenAI's ChatGPT model to generate summaries\n",
    "    | ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b79165",
   "metadata": {},
   "source": [
    "Summarize the documents in the `docs` list in batch using the `chain.batch` method.\n",
    "- Here, we set the `max_concurrency` parameter to 10 to allow up to 10 documents to be processed simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7fe3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling batches of documents\n",
    "summaries = summary_chain.batch(split_docs, {\"max_concurrency\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45363e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a11208",
   "metadata": {},
   "source": [
    "Print the summary to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "436bd00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
      "\n",
      "[summary]\n",
      "- 삼성전자가 온디바이스에서 작동 가능한 생성 AI 모델 '삼성 가우스'를 공개하였으며, 이 모델은 언어, 코드, 이미지의 3개 모델로 구성되어 있다.\n",
      "- '삼성 가우스'는 정규분포 이론을 정립한 수학자 가우스의 이름을 따왔으며, 다양한 상황에 최적화된 모델 선택이 가능하다.\n",
      "- 삼성전자는 이 AI 모델이 사용자 정보를 외부로 유출하지 않도록 설계되었으며, 향후 다양한 제품에 단계적으로 탑재할 계획이다.\n"
     ]
    }
   ],
   "source": [
    "# Prints the contents of the original document.\n",
    "print(split_docs[33].page_content, end=\"\\n\\n\")\n",
    "# Print a summary.\n",
    "print(\"[summary]\")\n",
    "print(summaries[33])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da5865",
   "metadata": {},
   "source": [
    "Initialize the `Chroma` vector store to index the child chunks. Use `OpenAIEmbeddings` as the embedding function.\n",
    "\n",
    "- Use `“doc_id”` as the key representing the document ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbe2f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Create a vector store to store the summary information.\n",
    "summary_vectorstore = Chroma(\n",
    "    collection_name=\"summaries\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "# Create a repository to store the parent document.\n",
    "store = InMemoryByteStore()\n",
    "\n",
    "# Specify a key name to store the document ID.\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Initialize the searcher (empty at startup).\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=summary_vectorstore,  # vector store\n",
    "    byte_store=store,  # byte store\n",
    "    id_key=id_key,  # document ID\n",
    ")\n",
    "# Create a document ID.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0e2c6",
   "metadata": {},
   "source": [
    "Save the summarized document and its metadata (here, the `Document ID` for the summary you created).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cec99148",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs = [\n",
    "    # Create a Document object with the summary as the page content and the document ID as metadata.\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb07ac1",
   "metadata": {},
   "source": [
    "The number of articles in the digest matches the number of original articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d36e4d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of documents in the summary\n",
    "len(summary_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400de8c",
   "metadata": {},
   "source": [
    "- Add `summary_docs` to the vector store with `retriever.vectorstore.add_documents(summary_docs)`.\n",
    "- Map `doc_ids` and `docs` with `retriever.docstore.mset(list(zip(doc_ids, docs))))` to store them in the document store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df7ce3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(\n",
    "    summary_docs\n",
    ")  # Add the summarized document to the vector repository.\n",
    "\n",
    "# Map the document ID to the document and store it in the document store.\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9158831",
   "metadata": {},
   "source": [
    "Perform a similarity search using the `similarity_search` method of the `vectorstore` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89e3d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search.\n",
    "result_docs = summary_vectorstore.similarity_search(\n",
    "    \"What is the name of the generative AI created by Samsung Electronics?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae7cb5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 삼성전자가 온디바이스에서 작동 가능한 생성 AI 모델 '삼성 가우스'를 공개하였으며, 이 모델은 언어, 코드, 이미지의 3개 모델로 구성되어 있다.\n",
      "- '삼성 가우스'는 정규분포 이론을 정립한 수학자 가우스의 이름을 따왔으며, 다양한 상황에 최적화된 모델 선택이 가능하다.\n",
      "- 삼성전자는 이 AI 모델이 사용자 정보를 외부로 유출하지 않도록 설계되었으며, 향후 다양한 제품에 단계적으로 탑재할 계획이다.\n"
     ]
    }
   ],
   "source": [
    "# Output 1 result document.\n",
    "print(result_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd64a80",
   "metadata": {},
   "source": [
    "Use the `invoke()` of the `retriever` object to retrieve documents related to your question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5a9c432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n"
     ]
    }
   ],
   "source": [
    "# Search for and fetch related articles.\n",
    "retrieved_docs = retriever.invoke(\n",
    "    \"What is the name of the generative AI created by Samsung Electronics?\"\n",
    ")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d5f1b",
   "metadata": {},
   "source": [
    "## Utilizing Hypothetical Queries to explore document content\n",
    "\n",
    "LLM can also be used to generate a list of questions that can be hypothesized about a particular document.\n",
    "\n",
    "These generated questions can be embedded to further explore and understand the content of the document.\n",
    "\n",
    "Generating hypothetical questions can help you identify key topics and concepts in your documentation, and can encourage readers to ask more questions about the content of your documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7933e03",
   "metadata": {},
   "source": [
    "Below is an example of creating a hypothesis question utilizing `Function Calling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5baf8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"hypothetical_questions\",  # Specify a name for the function.\n",
    "        \"description\": \"Generate hypothetical questions\",  # Write a description of the function.\n",
    "        \"parameters\": {  # Define the parameters of the function.\n",
    "            \"type\": \"object\",  # Specifies the type of the parameter as an object.\n",
    "            \"properties\": {  # Defines the properties of an object.\n",
    "                \"questions\": {  # Define the 'questions' attribute.\n",
    "                    \"type\": \"array\",  # Type 'questions' as an array.\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },  # Specifies the array's element type as String.\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"questions\"],  # Specify 'questions' as a required parameter.\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa557a",
   "metadata": {},
   "source": [
    "Use `ChatPromptTemplate` to define a prompt template that generates three hypothetical questions based on the given document.\n",
    "\n",
    "- Set `functions` and `function_call` to call the virtual question generation functions.\n",
    "- Use `JsonKeyOutputFunctionsParser` to parse the generated virtual questions and extract the values corresponding to the `questions` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cb4be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "hypothetical_query_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # We ask you to create exactly 3 hypothetical questions that you can answer using the documentation below. This number can be adjusted.\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"Generate a list of exactly 3 hypothetical questions that the below document could be used to answer. \"\n",
    "        \"Potential users are those interested in the AI industry. Create questions that they would be interested in. \"\n",
    "        \"Output should be written in Korean:\\n\\n{doc}\"\n",
    "    )\n",
    "    | ChatOpenAI(max_retries=0, model=\"gpt-4o-mini\").bind(\n",
    "        functions=functions, function_call={\"name\": \"hypothetical_questions\"}\n",
    "    )\n",
    "    # Extract the value corresponding to the “questions” key from the output.\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b789211",
   "metadata": {},
   "source": [
    "Output the answers to the documents.\n",
    "\n",
    "- The output contains the three Hypothetical Queries you created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9cda3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['삼성 가우스가 다른 생성 AI 모델과 비교했을 때 어떤 독창적인 기능을 제공할 수 있을까?',\n",
       " '온디바이스에서 작동하는 삼성 가우스가 개인 정보 보호에 미치는 영향은 무엇일까?',\n",
       " '삼성전자가 삼성 가우스를 다양한 제품에 탑재했을 때, 사용자 경험은 어떻게 변화할까?']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the chain for the given document.\n",
    "hypothetical_query_chain.invoke(split_docs[33])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ff912",
   "metadata": {},
   "source": [
    "Use the `chain.batch` method to process multiple requests for `split_docs` data at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac642190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch of hypothetical questions for a list of articles\n",
    "hypothetical_questions = hypothetical_query_chain.batch(\n",
    "    split_docs, {\"max_concurrency\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02840bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['삼성 가우스가 다른 생성 AI 모델과 비교하여 어떤 장점이 있을까요?',\n",
       " '온디바이스에서 작동하는 생성 AI 모델이 사용자의 개인정보 보호에 어떤 기여를 할 수 있을까요?',\n",
       " '삼성전자가 삼성 가우스를 다양한 제품에 탑재할 경우, 어떤 산업에서 가장 큰 영향을 미칠까요?']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothetical_questions[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364ded0",
   "metadata": {},
   "source": [
    "Below is the process for storing the Hypothetical Queries you created in Vector Storage, the same way we did before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c44404c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store to use for indexing child chunks\n",
    "hypothetical_vectorstore = Chroma(\n",
    "    collection_name=\"hypo-questions\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "# Storage hierarchy for parent documents\n",
    "store = InMemoryByteStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "# Retriever (empty on startup)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=hypothetical_vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]  # Create a document ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8a6b7",
   "metadata": {},
   "source": [
    "Add metadata (document IDs) to the `question_docs` list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7cbb65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_docs = []\n",
    "# save hypothetical_questions\n",
    "for i, question_list in enumerate(hypothetical_questions):\n",
    "    question_docs.extend(\n",
    "        # Create a Document object for each question in the list of questions, and include the document ID for that question in the metadata.\n",
    "        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a8e5f",
   "metadata": {},
   "source": [
    "Add the hypothesized query to the document, and add the original document to `docstore`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "105ecf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the hypothetical_questions document to the vector repository.\n",
    "retriever.vectorstore.add_documents(question_docs)\n",
    "\n",
    "# Map the document ID to the document and store it in the document store.\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb5835",
   "metadata": {},
   "source": [
    "Perform a similarity search using the `similarity_search` method of the `vectorstore` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca9afb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the vector repository for similar documents.\n",
    "result_docs = hypothetical_vectorstore.similarity_search(\n",
    "    \"What is the name of the generative AI created by Samsung Electronics?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce41e6",
   "metadata": {},
   "source": [
    "Below are the results of the similarity search.\n",
    "\n",
    "Here, we've only added the hypothesized query we created, so it returns the documents with the highest similarity among the hypothesized queries we created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10c33bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자의 생성 AI '삼성 가우스'가 향후 AI 기술 발전에 기여할 수 있는 방법은 무엇일까?\n",
      "{'doc_id': '556f29e3-eb73-40c7-ad82-e6c7b71631a3'}\n",
      "삼성에서 발표한 Generative AI 기술이 다른 기업들과의 경쟁에서 어떤 차별점을 제공할 수 있을까요?\n",
      "{'doc_id': '353584c8-8ee6-440f-8080-349d7c493bea'}\n",
      "삼성 가우스가 다른 생성 AI 모델과 비교하여 어떤 장점이 있을까요?\n",
      "{'doc_id': '6ef764f2-141f-45c0-abba-e170b2cdb406'}\n",
      "삼성 개발자 콘퍼런스 코리아 2023에서 발표된 내용을 바탕으로, 삼성의 AI 기술이 향후 산업에 미칠 영향은 무엇일까요?\n",
      "{'doc_id': '353584c8-8ee6-440f-8080-349d7c493bea'}\n"
     ]
    }
   ],
   "source": [
    "# Output the results of the similarity search.\n",
    "for doc in result_docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88722c7",
   "metadata": {},
   "source": [
    "Use the `invoke` method of the `retriever` object to retrieve documents related to the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d106a8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
      "▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개  ······································· 8\n",
      "   ▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································ 9\n",
      "   ▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10\n",
      "   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\n",
      "   ▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망··········································· 12\n",
      "   ▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································ 13\n"
     ]
    }
   ],
   "source": [
    "# Search for and fetch related articles.\n",
    "retrieved_docs = retriever.invoke(result_docs[1].page_content)\n",
    "\n",
    "# Output the documents found.\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-HnsOYzrZ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# FlashRank Reranker\n",
    "\n",
    "- Author: [Hwayoung Cha](https://github.com/forwardyoung)\n",
    "- Design: []()\n",
    "- Peer Review: []()\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "## Overview\n",
    "\n",
    "> [FlashRank](https://github.com/PrithivirajDamodaran/FlashRank) is an ultra-lightweight and ultra-fast Python library designed to add reranking to existing search and `retrieval` pipelines. It is based on state-of-the-art (`SoTA`) `cross-encoders`.\n",
    "\n",
    "This notebook introduces the use of `FlashRank-Reranker` within the LangChain framework, showcasing how to apply reranking techniques to improve the quality of search or `retrieval` results. It provides practical code examples and explanations for integrating `FlashRank` into a LangChain pipeline, highlighting its efficiency and effectiveness. The focus is on leveraging `FlashRank`'s capabilities to enhance the ranking of outputs in a streamlined and scalable way.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environement Setup](#environment-setup)"
   ],
   "id": "c69d1f48d21cd2b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ],
   "id": "c7431102d93a694f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T14:53:36.107286Z",
     "start_time": "2025-01-08T14:53:35.957725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "    }\n",
    ")"
   ],
   "id": "501e9dfa010f326a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can alternatively set OPENAI_API_KEY in .env file and load it.\n",
    "\n",
    "[Note] This is not necessary if you've already set OPENAI_API_KEY in previous steps."
   ],
   "id": "7d83ee066d91fb4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T14:53:36.123222Z",
     "start_time": "2025-01-08T14:53:36.108289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration file to manage API keys as environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key information\n",
    "load_dotenv(override=True)"
   ],
   "id": "abed94e9253ec29e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T14:53:36.127689Z",
     "start_time": "2025-01-08T14:53:36.124407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# install\n",
    "# !pip install -qU flashrank"
   ],
   "id": "e31774e423dd76fb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T14:53:36.133428Z",
     "start_time": "2025-01-08T14:53:36.128691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [\n",
    "                f\"Document {i+1}:\\n\\n{d.page_content}\\nMetadata: {d.metadata}\"\n",
    "                for i, d in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "    )"
   ],
   "id": "43856bcf1e8f0c63",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## FlashrankRerank\n",
    "\n",
    "Load data for a simple example and create a retriever."
   ],
   "id": "1c7d03faa97bf809"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T14:53:41.320899Z",
     "start_time": "2025-01-08T14:53:36.134653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load the documents\n",
    "documents = TextLoader(\"./data/appendix-keywords.txt\").load()\n",
    "\n",
    "# Initialized the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "# Split the documents\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Add a unique ID to each text\n",
    "for idx, text in enumerate(texts):\n",
    "    text.metadata[\"id\"] = idx\n",
    "    \n",
    "# Initialize the retriever\n",
    "retriever = FAISS.from_documents(\n",
    "    texts, OpenAIEmbeddings()\n",
    ").as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# query\n",
    "query = \"Tell me about Word2Vec\"\n",
    "\n",
    "# Search for documents\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "# Print the document\n",
    "pretty_print_docs(docs)"
   ],
   "id": "79d934121fd476be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Word2Vec\n",
      "Definition: Word2Vec is a technique in NLP that maps words to a vector space, representing their semantic relationships based on context.\n",
      "Example: In a Word2Vec model, \"king\" and \"queen\" are represented by vectors located close to each other.\n",
      "Related Keywords: Natural Language Processing (NLP), Embedding, Semantic Similarity\n",
      "Metadata: {'source': './data/appendix-keywords.txt', 'id': 12}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Embedding\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into low-dimensional continuous vectors that computers can process and understand.\n",
      "Example: The word \"apple\" can be represented as a vector like [0.65, -0.23, 0.17].\n",
      "Related Keywords: Natural Language Processing (NLP), Vectorization, Deep Learning\n",
      "Metadata: {'source': './data/appendix-keywords.txt', 'id': 1}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "VectorStore\n",
      "Definition: A VectorStore is a system designed to store data in vector format, enabling efficient retrieval, classification, and analysis tasks.\n",
      "Example: Storing word embedding vectors in a database for quick access during semantic search.\n",
      "Related Keywords: Embedding, Database, Vectorization\n",
      "Metadata: {'source': './data/appendix-keywords.txt', 'id': 4}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
      "Definition: TF-IDF is a statistical measure used to evaluate the importance of a word within a document by considering its frequency and rarity across a corpus.\n",
      "Example: Words with high TF-IDF values are often unique and critical for understanding the document.\n",
      "Related Keywords: Natural Language Processing (NLP), Information Retrieval, Data Mining\n",
      "Metadata: {'source': './data/appendix-keywords.txt', 'id': 18}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "GPT (Generative Pretrained Transformer)\n",
      "Definition: GPT is a generative language model pre-trained on vast datasets, capable of performing various text-based tasks. It generates natural and coherent text based on input.\n",
      "Example: A chatbot generating detailed answers to user queries is powered by GPT models.\n",
      "Related Keywords: Natural Language Processing (NLP), Text Generation, Deep Learning\n",
      "Metadata: {'source': './data/appendix-keywords.txt', 'id': 24}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      "Transformer\n",
      "Definition: A Transformer is a type of deep learning model widely used in natural language processing tasks like translation, summarization, and text generation. It is based on the Attention mechanism.\n",
      "Example: Google Translate utilizes a Transformer model for multilingual translation.\n",
      "Related Keywords: Deep Learning, Natural Language Processing (NLP), Attention mechanism\n",
      "Metadata: {'source': './data/appendix-keywords.txt', 'id': 8}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7:\n",
      "\n",
      "LLM (Large Language Model)\n",
      "Definition: LLMs are massive language models trained on large-scale text data, used for various natural language understanding and generation tasks.\n",
      "Example: OpenAI's GPT series is a prominent example of LLMs.\n",
      "Related Keywords: Natural Language Processing (NLP), Deep Learning, Text Generation\n",
      "Metadata: {'source': './data/appendix-keywords.txt', 'id': 13}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 8:\n",
      "\n",
      "HuggingFace\n",
      "Definition: HuggingFace is a library offering pre-trained models and tools for natural language processing, making NLP tasks accessible to researchers and developers.\n",
      "Example: HuggingFace's Transformers library can be used for sentiment analysis and text generation.\n",
      "Related Keywords: Natural Language Processing (NLP), Deep Learning, Library.\n",
      "Metadata: {'source': './data/appendix-keywords.txt', 'id': 9}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 9:\n",
      "\n",
      "Tokenizer\n",
      "Definition: A tokenizer is a tool that splits text data into tokens, often used for preprocessing in natural language processing tasks.\n",
      "Example: The sentence \"I love programming.\" is tokenized into [\"I\", \"love\", \"programming\", \".\"].\n",
      "Related Keywords: Tokenization, Natural Language Processing (NLP), Syntax Analysis.\n",
      "Metadata: {'source': './data/appendix-keywords.txt', 'id': 3}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 10:\n",
      "\n",
      "Semantic Search\n",
      "Definition: Semantic search is a search technique that understands the meaning of a user's query beyond simple keyword matching, returning results that are contextually relevant.\n",
      "Example: If a user searches for \"planets in the solar system,\" the system provides information about planets like Jupiter and Mars.\n",
      "Related Keywords: Natural Language Processing (NLP), Search Algorithms, Data Mining\n",
      "Metadata: {'source': './data/appendix-keywords.txt', 'id': 0}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's wrap the base `retriever` with a `ContextualCompressionRetriever` and use `FlashrankRerank` as the compressor.",
   "id": "ea07e244c9171d26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T14:53:42.781060Z",
     "start_time": "2025-01-08T14:53:41.323926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Initialize the FlshrankRerank\n",
    "compressor = FlashrankRerank(model=\"ms-marco-MultiBERT-L-12\")\n",
    "\n",
    "# Initialize the ContextualCompressioinRetriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "# Search for compressed documents\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"Tell me about Word2Vec.\"\n",
    ")\n",
    "\n",
    "# Print the document ID\n",
    "print([doc.metadata[\"id\"] for doc in compressed_docs])"
   ],
   "id": "23a21f9f025132c5",
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "`FlashrankRerank` is not fully defined; you should define `Ranker`, then call `FlashrankRerank.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.9/u/class-not-fully-defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPydanticUserError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m llm \u001B[38;5;241m=\u001B[39m ChatOpenAI(temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Initialize the FlshrankRerank\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m compressor \u001B[38;5;241m=\u001B[39m \u001B[43mFlashrankRerank\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mms-marco-MultiBERT-L-12\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Initialize the ContextualCompressioinRetriever\u001B[39;00m\n\u001B[0;32m     12\u001B[0m compression_retriever \u001B[38;5;241m=\u001B[39m ContextualCompressionRetriever(\n\u001B[0;32m     13\u001B[0m     base_compressor\u001B[38;5;241m=\u001B[39mcompressor, base_retriever\u001B[38;5;241m=\u001B[39mretriever\n\u001B[0;32m     14\u001B[0m )\n",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-GHgbjDj7-py3.11\\Lib\\site-packages\\pydantic\\_internal\\_mock_val_ser.py:99\u001B[0m, in \u001B[0;36mMockValSer.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;66;03m# raise an AttributeError if `item` doesn't exist\u001B[39;00m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_val_or_ser, item)\n\u001B[1;32m---> 99\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m PydanticUserError(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_message, code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_code)\n",
      "\u001B[1;31mPydanticUserError\u001B[0m: `FlashrankRerank` is not fully defined; you should define `Ranker`, then call `FlashrankRerank.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.9/u/class-not-fully-defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compare the results after reanker is applied.",
   "id": "4a147fc787860bac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print the results of document compressions\n",
    "pretty_print_docs(compressed_docs)"
   ],
   "id": "732f27a4e8b3d4cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation using RAGAS\n",
    "\n",
    "- Author: [Sungchul Kim](https://github.com/rlatjcj)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/16-Evaluations/02-Evaluation-using-RAGAS.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/16-Evaluations/02-Evaluation-using-RAGAS.ipynb)\n",
    "\n",
    "## Overview\n",
    "This tutorial will show you how to evaluate the quality of your LLM output using RAGAS.\n",
    "\n",
    "Before starting this tutorial, let's review the RAGAS metrics, Context Recall, Context Precision, Answer Relevancy, and Faithfulness first.\n",
    "\n",
    "### Context Recall\n",
    "\n",
    "It estimates \"how well the retrieved context matches the LLM-generated answer\".  \n",
    "It is calculated using question, ground truth, and retrieved context. The value is between 0 and 1, and higher values indicate better performance. To estimate context recall from the ground truth answer, each claim in the ground truth answer is analyzed to see if it can be attributed to the retrieved context. In the ideal scenario, all claims in the ground truth answer should be able to be attributed to the retrieved context.\n",
    "\n",
    "$$\\text{context recall} = \\frac{|\\text{GT claims that can be attributed to context}|}{|\\text{Number of claims in GT}|}$$\n",
    "\n",
    "\n",
    "### Context Precision\n",
    "\n",
    "It estimates \"whether ground-truth related items in contexts are ranked at the top\".\n",
    "\n",
    "Ideally, all relevant chunks should appear in the top ranks. This metric is calculated using question, ground_truth, and contexts, with values ranging from 0 to 1. Higher scores indicate better precision.\n",
    "\n",
    "The formula for Context Precision@K is as follows:\n",
    "\n",
    "$$\\text{Context Precision@K} = \\frac{\\sum_{k=1}^{K} (\\text{Precision@k} \\times v_k)}{\\text{Total number of relevant items in the top K results}}$$\n",
    "\n",
    "Here, Precision@k is calculated as follows:\n",
    "\n",
    "$$\\text{Precision@k} = \\frac{\\text{true positives@k}}{(\\text{true positives@k + false positives@k})}$$\n",
    "\n",
    "K is the total number of chunks in contexts, and $v_k \\in \\{0, 1\\}$ is the relevance indicator at rank k.\n",
    "\n",
    "This metric is used to evaluate the quality of the retrieved context in information retrieval systems. It measures how well relevant information is placed in the top ranks, allowing for performance assessment.\n",
    "\n",
    "\n",
    "### Answer Relevancy\n",
    "\n",
    "It is a metric that evaluates \"how well the generated answer matches the given prompt\".\n",
    "\n",
    "The main features and calculation methods of this metric are as follows:\n",
    "\n",
    "1. Purpose: Evaluate the relevance of the generated answer.\n",
    "2. Score interpretation: Lower scores indicate incomplete or duplicate information in the answer, while higher scores indicate better relevance.\n",
    "3. Elements used in calculation: question, context, answer\n",
    "\n",
    "The calculation method for Answer Relevancy is defined as the average cosine similarity between the original question and the generated synthetic questions.\n",
    "\n",
    "$$\\text{answer relevancy} = \\frac{1}{N} \\sum_{i=1}^N \\cos(E_{g_i}, E_o)$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\text{answer relevancy} = \\frac{1}{N} \\sum_{i=1}^N \\frac{E_{g_i} \\cdot E_o}{\\|E_{g_i}\\| \\|E_o\\|}$$\n",
    "\n",
    "Here:\n",
    "- $E_{g_i}$ is the embedding of the generated question $i$\n",
    "- $E_o$ is the embedding of the original question\n",
    "- $N$ is the number of generated questions (default value is 3)\n",
    "\n",
    "Note:\n",
    "- The actual score is mostly between 0 and 1, but mathematically it can be between -1 and 1 due to the characteristics of cosine similarity.\n",
    "\n",
    "This metric is useful for evaluating the performance of question-answering systems, particularly for measuring how well the generated answer reflects the original question's intent.\n",
    "\n",
    "\n",
    "### Faithfulness\n",
    "\n",
    "It is a metric that evaluates \"the factual consistency of the generated answer compared to the given context\".\n",
    "\n",
    "The main features and calculation methods of this metric are as follows:\n",
    "\n",
    "1. Purpose: Evaluate the factual consistency of the generated answer compared to the given context.\n",
    "2. Calculation elements: Use the generated answer and the retrieved context.\n",
    "3. Score range: Adjusted between 0 and 1, with higher values indicating better performance.\n",
    "\n",
    "The calculation method for Faithfulness score is as follows:\n",
    "\n",
    "$$\\text{Faithfulness score} = \\frac{|\\text{Number of claims in the generated answer that can be inferred from given context}|}{|\\text{Total number of claims in the generated answer}|}$$\n",
    "\n",
    "Calculation process:\n",
    "1. Identify claims in the generated answer.\n",
    "2. Verify each claim against the given context to check if it can be inferred from the context.\n",
    "3. Use the above formula to calculate the score.\n",
    "\n",
    "Example:\n",
    "- Question: \"When and where was Einstein born?\"\n",
    "- Context: \"Albert Einstein (born March 14, 1879) is a German-born theoretical physicist, widely considered one of the most influential scientists of all time.\"\n",
    "- High faithfulness answer: \"Einstein was born in Germany on March 14, 1879.\"\n",
    "- Low faithfulness answer: \"Einstein was born in Germany on March 20, 1879.\"\n",
    "\n",
    "This metric is useful for evaluating the performance of question-answering systems, particularly for measuring how well the generated answer reflects the given context.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "### References\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial ragas pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_text_splitters\",\n",
    "        \"langchain_openai\",\n",
    "        \"ragas\",\n",
    "        \"pymupdf\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Evaluation-using-RAGAS\",  # title 과 동일하게 설정해 주세요\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set API keys such as `OPENAI_API_KEY` in a `.env` file and load them.\n",
    "\n",
    "[Note] This is not necessary if you've already set the required API keys in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load API keys from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved RAGAS dataset\n",
    "\n",
    "Load the RAGAS dataset that you saved in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What specific recent developments in generativ...</td>\n",
       "      <td>['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 A...</td>\n",
       "      <td>TechRepublic highlighted several recent develo...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the dates and location for CES 2024?</td>\n",
       "      <td>['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...</td>\n",
       "      <td>CES 2024 will take place from January 9 to Jan...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the key aspects of AI global cooperat...</td>\n",
       "      <td>['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발...</td>\n",
       "      <td>The key aspects of AI global cooperation highl...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What measures are suggested to enhance data pr...</td>\n",
       "      <td>['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알...</td>\n",
       "      <td>The context suggests several measures to enhan...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What were the main takeaways from the AI Safet...</td>\n",
       "      <td>['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해...</td>\n",
       "      <td>The main takeaways from the AI Safety Summit o...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What specific recent developments in generativ...   \n",
       "1      What are the dates and location for CES 2024?   \n",
       "2  What are the key aspects of AI global cooperat...   \n",
       "3  What measures are suggested to enhance data pr...   \n",
       "4  What were the main takeaways from the AI Safet...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 A...   \n",
       "1  ['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...   \n",
       "2  ['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발...   \n",
       "3  ['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알...   \n",
       "4  ['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  TechRepublic highlighted several recent develo...         simple   \n",
       "1  CES 2024 will take place from January 9 to Jan...         simple   \n",
       "2  The key aspects of AI global cooperation highl...         simple   \n",
       "3  The context suggests several measures to enhan...         simple   \n",
       "4  The main takeaways from the AI Safety Summit o...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "1  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "2  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "3  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "4  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/ragas_synthetic_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "test_dataset = Dataset.from_pandas(df)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475a0e694d0e49f4beac171466f7f137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "# Convert contexts column from string to list\n",
    "def convert_to_list(example):\n",
    "    contexts = ast.literal_eval(example[\"contexts\"])\n",
    "    return {\"contexts\": contexts}\n",
    "\n",
    "\n",
    "test_dataset = test_dataset.map(convert_to_list)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등\\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n- CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며,\\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한\\nCES 2024\\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\n- 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는\\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한\\n지식과 최신 연구 결과 공유\\n- 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를\\n논의하고, 학계, 산업계의 연구자와 실무자들에게 해당 분\\nAIMLA 2024\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\nhttps://ccnet2024.org/aimla\\n2024.1.27~28 덴마크, 코펜하겐\\n/index\\n- AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야\\n연구원, 실무자, 과학자, 학생 및 공학자 간 교류의 기회 제공\\n- 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사,\\nAAAI Conference\\n워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프\\non Artificial\\n로그램 등 진행\\nIntelligence\\n기간 장소 홈페이지\\nhttps://aaai.org/aaai-confere\\n2024.2.20~27 캐나다, 밴쿠버\\nnce/']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1][\"contexts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# Step 1: Load Documents\n",
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\") # TODO (sungchul): update the path\n",
    "docs = loader.load()\n",
    "\n",
    "# Step 2: Split Documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# Step 3: Create Embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Step 4: Create DB and Save\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "\n",
    "# Step 5: Create Retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Step 6: Create Prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# Step 7: Create LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Step 8: Create Chain\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create batch dataset. Batch dataset is useful when you want to process a large number of questions at once.\n",
    "\n",
    "- Reference for `batch`: [Link](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/07-LCEL-Interface.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What specific recent developments in generative AI have been highlighted by TechRepublic in their November 2023 articles?',\n",
       " 'What are the dates and location for CES 2024?',\n",
       " \"What are the key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems?\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dataset = [question for question in test_dataset[\"question\"]]\n",
    "batch_dataset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `batch()` to get answers for the batch dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't know. The provided context does not contain information about specific recent developments in generative AI highlighted by TechRepublic in their November 2023 articles.\",\n",
       " 'The dates for CES 2024 are January 9 to January 12, and it will be held in Las Vegas, USA.',\n",
       " \"The key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems include:\\n\\n1. **International Code of Conduct**: The G7 has developed an International Code of Conduct for Advanced AI Systems, which encourages companies to voluntarily adopt measures for identifying and mitigating AI risks throughout the AI lifecycle.\\n\\n2. **Risk Assessment and Mitigation**: The code emphasizes the importance of assessing and mitigating risks associated with advanced AI systems, both during development and after deployment, to address vulnerabilities and misuse.\\n\\n3. **Transparency and Accountability**: It calls for transparency in disclosing the performance and limitations of AI systems and strengthening accountability by informing appropriate and inappropriate use cases.\\n\\n4. **Information Sharing and Collaboration**: The G7 promotes collaboration among industry, government, civil society, and academia for information sharing and incident reporting, aiming to establish AI governance and risk management policies based on a risk-based approach.\\n\\n5. **Security Controls**: The implementation of robust security controls, including physical security, cybersecurity, and insider threat protection, is encouraged throughout the AI lifecycle.\\n\\n6. **Content Authentication**: The development and implementation of mechanisms, such as watermarks, to authenticate AI-generated content and verify its source are recommended.\\n\\n7. **Research and Investment**: Prioritizing research and investment in mitigating social risks and addressing global challenges like climate change, global health, and education through advanced AI systems.\\n\\n8. **International Standards and Data Protection**: The G7 aims to accelerate the development and adoption of international technical standards and implement appropriate safeguards for data input and collection to protect privacy and intellectual property rights.\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = chain.batch(batch_dataset)\n",
    "answer[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the answers generated by the LLM in the 'answer' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungchul/workspace/src/side_projects/LangChain-OpenTutorial/.venv/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sungchul/workspace/src/side_projects/LangChain-OpenTutorial/.venv/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Overwrite or add 'answer' column\n",
    "if \"answer\" in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns([\"answer\"]).add_column(\"answer\", answer)\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column(\"answer\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b9ab427f7f46d997b2972dfb0c90d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.7000, 'faithfulness': 0.5094, 'answer_relevancy': 0.5897, 'context_recall': 0.5333}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=test_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What specific recent developments in generativ...</td>\n",
       "      <td>[SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI...</td>\n",
       "      <td>I don't know. The provided context does not co...</td>\n",
       "      <td>TechRepublic highlighted several recent develo...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the dates and location for CES 2024?</td>\n",
       "      <td>[Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CT...</td>\n",
       "      <td>The dates for CES 2024 are January 9 to Januar...</td>\n",
       "      <td>CES 2024 will take place from January 9 to Jan...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957657</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the key aspects of AI global cooperat...</td>\n",
       "      <td>[문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발하...</td>\n",
       "      <td>The key aspects of AI global cooperation highl...</td>\n",
       "      <td>The key aspects of AI global cooperation highl...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What measures are suggested to enhance data pr...</td>\n",
       "      <td>[∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리...</td>\n",
       "      <td>To enhance data privacy in the context of adva...</td>\n",
       "      <td>The context suggests several measures to enhan...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995689</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What were the main takeaways from the AI Safet...</td>\n",
       "      <td>[관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 ...</td>\n",
       "      <td>The main takeaways from the AI Safety Summit o...</td>\n",
       "      <td>The main takeaways from the AI Safety Summit o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What specific recent developments in generativ...   \n",
       "1      What are the dates and location for CES 2024?   \n",
       "2  What are the key aspects of AI global cooperat...   \n",
       "3  What measures are suggested to enhance data pr...   \n",
       "4  What were the main takeaways from the AI Safet...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI...   \n",
       "1  [Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CT...   \n",
       "2  [문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발하...   \n",
       "3  [∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리...   \n",
       "4  [관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  I don't know. The provided context does not co...   \n",
       "1  The dates for CES 2024 are January 9 to Januar...   \n",
       "2  The key aspects of AI global cooperation highl...   \n",
       "3  To enhance data privacy in the context of adva...   \n",
       "4  The main takeaways from the AI Safety Summit o...   \n",
       "\n",
       "                                           reference  context_precision  \\\n",
       "0  TechRepublic highlighted several recent develo...                0.5   \n",
       "1  CES 2024 will take place from January 9 to Jan...                1.0   \n",
       "2  The key aspects of AI global cooperation highl...                0.5   \n",
       "3  The context suggests several measures to enhan...                1.0   \n",
       "4  The main takeaways from the AI Safety Summit o...                1.0   \n",
       "\n",
       "   faithfulness  answer_relevancy  context_recall  \n",
       "0      0.333333          0.000000        0.600000  \n",
       "1      1.000000          0.957657        1.000000  \n",
       "2      0.500000          1.000000        0.400000  \n",
       "3      1.000000          0.995689        0.500000  \n",
       "4      0.111111          1.000000        0.666667  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result.to_pandas()\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"data/ragas_evaluation_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957657</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995689</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.952757</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.990732</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_precision  faithfulness  answer_relevancy  context_recall\n",
       "0                0.5      0.333333          0.000000        0.600000\n",
       "1                1.0      1.000000          0.957657        1.000000\n",
       "2                0.5      0.500000          1.000000        0.400000\n",
       "3                1.0      1.000000          0.995689        0.500000\n",
       "4                1.0      0.111111          1.000000        0.666667\n",
       "5                0.0      0.000000          0.000000        1.000000\n",
       "6                1.0      0.733333          0.952757        0.666667\n",
       "7                1.0      0.916667          0.990732        0.500000\n",
       "8                0.0      0.500000          0.000000        0.000000\n",
       "9                1.0      0.000000          0.000000        0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[:, \"context_precision\":\"context_recall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
